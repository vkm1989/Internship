{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01412320",
   "metadata": {},
   "source": [
    "#                                                ASSIGNMENT-1\n",
    "                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a788db",
   "metadata": {},
   "source": [
    "#                                          WEB SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d055aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\programdata\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arso (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "# First install libraries\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd0db6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df10fa",
   "metadata": {},
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc4451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "wkpd = requests.get('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb164d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wkpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038e9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page content\n",
    "\n",
    "bsup = BeautifulSoup(wkpd.content)\n",
    "#print(bsup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5a6d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n",
      "Navigation menu\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "Namespaces\n",
      "\n",
      "\n",
      "Views\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "Navigation\n",
      "\n",
      "\n",
      "Contribute\n",
      "\n",
      "\n",
      "Tools\n",
      "\n",
      "\n",
      "Print/export\n",
      "\n",
      "\n",
      "In other projects\n",
      "\n",
      "\n",
      "Languages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "header = bsup.find_all(['h1', 'h2', 'h3'])\n",
    "\n",
    "for i in header:\n",
    "    print(i.get_text())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b407a",
   "metadata": {},
   "source": [
    "# 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48f6896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "imdb_page = requests.get('https://www.imdb.com/chart/top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2eb69542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48a372da",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(imdb_page.content)\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e54ebc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1.', 'The', 'Shawshank', 'Redemption', '(1994)'],\n",
       " ['2.', 'The', 'Godfather', '(1972)'],\n",
       " ['3.', 'The', 'Dark', 'Knight', '(2008)'],\n",
       " ['4.', 'The', 'Godfather', 'Part', 'II', '(1974)'],\n",
       " ['5.', '12', 'Angry', 'Men', '(1957)'],\n",
       " ['6.', \"Schindler's\", 'List', '(1993)'],\n",
       " ['7.',\n",
       "  'The',\n",
       "  'Lord',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Rings:',\n",
       "  'The',\n",
       "  'Return',\n",
       "  'of',\n",
       "  'the',\n",
       "  'King',\n",
       "  '(2003)'],\n",
       " ['8.', 'Pulp', 'Fiction', '(1994)'],\n",
       " ['9.',\n",
       "  'The',\n",
       "  'Lord',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Rings:',\n",
       "  'The',\n",
       "  'Fellowship',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Ring',\n",
       "  '(2001)'],\n",
       " ['10.', 'Il', 'buono,', 'il', 'brutto,', 'il', 'cattivo', '(1966)'],\n",
       " ['11.', 'Forrest', 'Gump', '(1994)'],\n",
       " ['12.', 'Fight', 'Club', '(1999)'],\n",
       " ['13.', 'Inception', '(2010)'],\n",
       " ['14.',\n",
       "  'The',\n",
       "  'Lord',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Rings:',\n",
       "  'The',\n",
       "  'Two',\n",
       "  'Towers',\n",
       "  '(2002)'],\n",
       " ['15.', 'The', 'Empire', 'Strikes', 'Back', '(1980)'],\n",
       " ['16.', 'The', 'Matrix', '(1999)'],\n",
       " ['17.', 'Goodfellas', '(1990)'],\n",
       " ['18.', 'One', 'Flew', 'Over', 'the', \"Cuckoo's\", 'Nest', '(1975)'],\n",
       " ['19.', 'Se7en', '(1995)'],\n",
       " ['20.', 'Shichinin', 'no', 'samurai', '(1954)'],\n",
       " ['21.', \"It's\", 'a', 'Wonderful', 'Life', '(1946)'],\n",
       " ['22.', 'The', 'Silence', 'of', 'the', 'Lambs', '(1991)'],\n",
       " ['23.', 'Cidade', 'de', 'Deus', '(2002)'],\n",
       " ['24.', 'Saving', 'Private', 'Ryan', '(1998)'],\n",
       " ['25.', 'La', 'vita', 'è', 'bella', '(1997)'],\n",
       " ['26.', 'The', 'Green', 'Mile', '(1999)'],\n",
       " ['27.', 'Interstellar', '(2014)'],\n",
       " ['28.', 'Star', 'Wars', '(1977)'],\n",
       " ['29.', 'Terminator', '2:', 'Judgment', 'Day', '(1991)'],\n",
       " ['30.', 'Back', 'to', 'the', 'Future', '(1985)'],\n",
       " ['31.', 'Sen', 'to', 'Chihiro', 'no', 'kamikakushi', '(2001)'],\n",
       " ['32.', 'Psycho', '(1960)'],\n",
       " ['33.', 'The', 'Pianist', '(2002)'],\n",
       " ['34.', 'Léon', '(1994)'],\n",
       " ['35.', 'Gisaengchung', '(2019)'],\n",
       " ['36.', 'The', 'Lion', 'King', '(1994)'],\n",
       " ['37.', 'Gladiator', '(2000)'],\n",
       " ['38.', 'American', 'History', 'X', '(1998)'],\n",
       " ['39.', 'The', 'Departed', '(2006)'],\n",
       " ['40.', 'The', 'Usual', 'Suspects', '(1995)'],\n",
       " ['41.', 'The', 'Prestige', '(2006)'],\n",
       " ['42.', 'Casablanca', '(1942)'],\n",
       " ['43.', 'Whiplash', '(2014)'],\n",
       " ['44.', 'The', 'Intouchables', '(2011)'],\n",
       " ['45.', 'Hotaru', 'no', 'haka', '(1988)'],\n",
       " ['46.', 'Seppuku', '(1962)'],\n",
       " ['47.', 'Modern', 'Times', '(1936)'],\n",
       " ['48.', 'Once', 'Upon', 'a', 'Time', 'in', 'the', 'West', '(1968)'],\n",
       " ['49.', 'Rear', 'Window', '(1954)'],\n",
       " ['50.', 'Alien', '(1979)'],\n",
       " ['51.', 'City', 'Lights', '(1931)'],\n",
       " ['52.', 'Nuovo', 'Cinema', 'Paradiso', '(1988)'],\n",
       " ['53.', 'Apocalypse', 'Now', '(1979)'],\n",
       " ['54.', 'Memento', '(2000)'],\n",
       " ['55.', 'Raiders', 'of', 'the', 'Lost', 'Ark', '(1981)'],\n",
       " ['56.', 'Django', 'Unchained', '(2012)'],\n",
       " ['57.', 'WALL·E', '(2008)'],\n",
       " ['58.', 'The', 'Lives', 'of', 'Others', '(2006)'],\n",
       " ['59.', 'Sunset', 'Blvd.', '(1950)'],\n",
       " ['60.', 'Paths', 'of', 'Glory', '(1957)'],\n",
       " ['61.', 'The', 'Shining', '(1980)'],\n",
       " ['62.', 'The', 'Great', 'Dictator', '(1940)'],\n",
       " ['63.', 'Avengers:', 'Infinity', 'War', '(2018)'],\n",
       " ['64.', 'Witness', 'for', 'the', 'Prosecution', '(1957)'],\n",
       " ['65.', 'Aliens', '(1986)'],\n",
       " ['66.', 'American', 'Beauty', '(1999)'],\n",
       " ['67.', 'Spider-Man:', 'Into', 'the', 'Spider-Verse', '(2018)'],\n",
       " ['68.', 'Top', 'Gun:', 'Maverick', '(2022)'],\n",
       " ['69.',\n",
       "  'Dr.',\n",
       "  'Strangelove',\n",
       "  'or:',\n",
       "  'How',\n",
       "  'I',\n",
       "  'Learned',\n",
       "  'to',\n",
       "  'Stop',\n",
       "  'Worrying',\n",
       "  'and',\n",
       "  'Love',\n",
       "  'the',\n",
       "  'Bomb',\n",
       "  '(1964)'],\n",
       " ['70.', 'The', 'Dark', 'Knight', 'Rises', '(2012)'],\n",
       " ['71.', 'Oldeuboi', '(2003)'],\n",
       " ['72.', 'Joker', '(2019)'],\n",
       " ['73.', 'Amadeus', '(1984)'],\n",
       " ['74.', 'Braveheart', '(1995)'],\n",
       " ['75.', 'Toy', 'Story', '(1995)'],\n",
       " ['76.', 'Coco', '(2017)'],\n",
       " ['77.', 'Inglourious', 'Basterds', '(2009)'],\n",
       " ['78.', 'Das', 'Boot', '(1981)'],\n",
       " ['79.', 'Avengers:', 'Endgame', '(2019)'],\n",
       " ['80.', 'Mononoke-hime', '(1997)'],\n",
       " ['81.', 'Once', 'Upon', 'a', 'Time', 'in', 'America', '(1984)'],\n",
       " ['82.', 'Good', 'Will', 'Hunting', '(1997)'],\n",
       " ['83.', 'Kimi', 'no', 'na', 'wa.', '(2016)'],\n",
       " ['84.', 'Requiem', 'for', 'a', 'Dream', '(2000)'],\n",
       " ['85.', 'Toy', 'Story', '3', '(2010)'],\n",
       " ['86.', \"Singin'\", 'in', 'the', 'Rain', '(1952)'],\n",
       " ['87.', '3', 'Idiots', '(2009)'],\n",
       " ['88.', 'Tengoku', 'to', 'jigoku', '(1963)'],\n",
       " ['89.',\n",
       "  'Star',\n",
       "  'Wars:',\n",
       "  'Episode',\n",
       "  'VI',\n",
       "  '-',\n",
       "  'Return',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Jedi',\n",
       "  '(1983)'],\n",
       " ['90.', '2001:', 'A', 'Space', 'Odyssey', '(1968)'],\n",
       " ['91.', 'Eternal', 'Sunshine', 'of', 'the', 'Spotless', 'Mind', '(2004)'],\n",
       " ['92.', 'Reservoir', 'Dogs', '(1992)'],\n",
       " ['93.', 'Capharnaüm', '(2018)'],\n",
       " ['94.', 'Jagten', '(2012)'],\n",
       " ['95.', 'Lawrence', 'of', 'Arabia', '(1962)'],\n",
       " ['96.', 'Citizen', 'Kane', '(1941)'],\n",
       " ['97.', 'M', '-', 'Eine', 'Stadt', 'sucht', 'einen', 'Mörder', '(1931)'],\n",
       " ['98.', 'North', 'by', 'Northwest', '(1959)'],\n",
       " ['99.', 'Idi', 'i', 'smotri', '(1985)'],\n",
       " ['100.', 'Vertigo', '(1958)'],\n",
       " ['101.', 'Le', 'fabuleux', 'destin', \"d'Amélie\", 'Poulain', '(2001)'],\n",
       " ['102.', 'A', 'Clockwork', 'Orange', '(1971)'],\n",
       " ['103.', 'Double', 'Indemnity', '(1944)'],\n",
       " ['104.', 'The', 'Apartment', '(1960)'],\n",
       " ['105.', 'Full', 'Metal', 'Jacket', '(1987)'],\n",
       " ['106.', 'Ikiru', '(1952)'],\n",
       " ['107.', 'Scarface', '(1983)'],\n",
       " ['108.', 'To', 'Kill', 'a', 'Mockingbird', '(1962)'],\n",
       " ['109.', 'The', 'Sting', '(1973)'],\n",
       " ['110.', 'Hamilton', '(2020)'],\n",
       " ['111.', 'Heat', '(1995)'],\n",
       " ['112.', 'Taxi', 'Driver', '(1976)'],\n",
       " ['113.', 'Up', '(2009)'],\n",
       " ['114.', 'Incendies', '(2010)'],\n",
       " ['115.', 'L.A.', 'Confidential', '(1997)'],\n",
       " ['116.', 'Jodaeiye', 'Nader', 'az', 'Simin', '(2011)'],\n",
       " ['117.', 'Metropolis', '(1927)'],\n",
       " ['118.', 'Die', 'Hard', '(1988)'],\n",
       " ['119.', 'Snatch', '(2000)'],\n",
       " ['120.', 'Ladri', 'di', 'biciclette', '(1948)'],\n",
       " ['121.', 'Indiana', 'Jones', 'and', 'the', 'Last', 'Crusade', '(1989)'],\n",
       " ['122.', '1917', '(2019)'],\n",
       " ['123.', 'Taare', 'Zameen', 'Par', '(2007)'],\n",
       " ['124.', 'Der', 'Untergang', '(2004)'],\n",
       " ['125.', 'Per', 'qualche', 'dollaro', 'in', 'più', '(1965)'],\n",
       " ['126.', 'Batman', 'Begins', '(2005)'],\n",
       " ['127.', 'Dangal', '(2016)'],\n",
       " ['128.', 'The', 'Kid', '(1921)'],\n",
       " ['129.', 'Some', 'Like', 'It', 'Hot', '(1959)'],\n",
       " ['130.', 'All', 'About', 'Eve', '(1950)'],\n",
       " ['131.', 'The', 'Father', '(2020)'],\n",
       " ['132.', 'Green', 'Book', '(2018)'],\n",
       " ['133.', 'The', 'Wolf', 'of', 'Wall', 'Street', '(2013)'],\n",
       " ['134.', 'Judgment', 'at', 'Nuremberg', '(1961)'],\n",
       " ['135.', 'Ran', '(1985)'],\n",
       " ['136.', 'Casino', '(1995)'],\n",
       " ['137.', 'Spider-Man:', 'No', 'Way', 'Home', '(2021)'],\n",
       " ['138.', 'Unforgiven', '(1992)'],\n",
       " ['139.', \"Pan's\", 'Labyrinth', '(2006)'],\n",
       " ['140.', 'There', 'Will', 'Be', 'Blood', '(2007)'],\n",
       " ['141.', 'The', 'Truman', 'Show', '(1998)'],\n",
       " ['142.', 'The', 'Sixth', 'Sense', '(1999)'],\n",
       " ['143.', 'A', 'Beautiful', 'Mind', '(2001)'],\n",
       " ['144.', 'Monty', 'Python', 'and', 'the', 'Holy', 'Grail', '(1975)'],\n",
       " ['145.', 'Yôjinbô', '(1961)'],\n",
       " ['146.', 'The', 'Treasure', 'of', 'the', 'Sierra', 'Madre', '(1948)'],\n",
       " ['147.', 'Shutter', 'Island', '(2010)'],\n",
       " ['148.', 'Jurassic', 'Park', '(1993)'],\n",
       " ['149.', 'Rashômon', '(1950)'],\n",
       " ['150.', 'The', 'Great', 'Escape', '(1963)'],\n",
       " ['151.', 'Kill', 'Bill:', 'Vol.', '1', '(2003)'],\n",
       " ['152.', 'No', 'Country', 'for', 'Old', 'Men', '(2007)'],\n",
       " ['153.', 'Finding', 'Nemo', '(2003)'],\n",
       " ['154.', 'The', 'Elephant', 'Man', '(1980)'],\n",
       " ['155.', 'Chinatown', '(1974)'],\n",
       " ['156.', 'Raging', 'Bull', '(1980)'],\n",
       " ['157.', 'The', 'Thing', '(1982)'],\n",
       " ['158.', 'Gone', 'with', 'the', 'Wind', '(1939)'],\n",
       " ['159.', 'V', 'for', 'Vendetta', '(2005)'],\n",
       " ['160.', 'Inside', 'Out', '(2015)'],\n",
       " ['161.', 'Lock,', 'Stock', 'and', 'Two', 'Smoking', 'Barrels', '(1998)'],\n",
       " ['162.', 'Dial', 'M', 'for', 'Murder', '(1954)'],\n",
       " ['163.', 'El', 'secreto', 'de', 'sus', 'ojos', '(2009)'],\n",
       " ['164.', 'Hauru', 'no', 'ugoku', 'shiro', '(2004)'],\n",
       " ['165.', 'The', 'Bridge', 'on', 'the', 'River', 'Kwai', '(1957)'],\n",
       " ['166.', 'Three', 'Billboards', 'Outside', 'Ebbing,', 'Missouri', '(2017)'],\n",
       " ['167.', 'Trainspotting', '(1996)'],\n",
       " ['168.', 'Warrior', '(2011)'],\n",
       " ['169.', 'Gran', 'Torino', '(2008)'],\n",
       " ['170.', 'Fargo', '(1996)'],\n",
       " ['171.', 'Prisoners', '(2013)'],\n",
       " ['172.', 'Tonari', 'no', 'Totoro', '(1988)'],\n",
       " ['173.', 'Million', 'Dollar', 'Baby', '(2004)'],\n",
       " ['174.', 'Catch', 'Me', 'If', 'You', 'Can', '(2002)'],\n",
       " ['175.', 'The', 'Gold', 'Rush', '(1925)'],\n",
       " ['176.', 'Blade', 'Runner', '(1982)'],\n",
       " ['177.', 'Bacheha-Ye', 'aseman', '(1997)'],\n",
       " ['178.', 'On', 'the', 'Waterfront', '(1954)'],\n",
       " ['179.', 'The', 'Third', 'Man', '(1949)'],\n",
       " ['180.', 'Before', 'Sunrise', '(1995)'],\n",
       " ['181.', '12', 'Years', 'a', 'Slave', '(2013)'],\n",
       " ['182.', 'Ben-Hur', '(1959)'],\n",
       " ['183.', 'Smultronstället', '(1957)'],\n",
       " ['184.',\n",
       "  'Harry',\n",
       "  'Potter',\n",
       "  'and',\n",
       "  'the',\n",
       "  'Deathly',\n",
       "  'Hallows:',\n",
       "  'Part',\n",
       "  '2',\n",
       "  '(2011)'],\n",
       " ['185.', 'Gone', 'Girl', '(2014)'],\n",
       " ['186.', 'The', 'General', '(1926)'],\n",
       " ['187.', 'The', 'Deer', 'Hunter', '(1978)'],\n",
       " ['188.', 'In', 'the', 'Name', 'of', 'the', 'Father', '(1993)'],\n",
       " ['189.', 'The', 'Grand', 'Budapest', 'Hotel', '(2014)'],\n",
       " ['190.', 'Le', 'salaire', 'de', 'la', 'peur', '(1953)'],\n",
       " ['191.', 'Barry', 'Lyndon', '(1975)'],\n",
       " ['192.', 'Mr.', 'Smith', 'Goes', 'to', 'Washington', '(1939)'],\n",
       " ['193.', 'Sherlock', 'Jr.', '(1924)'],\n",
       " ['194.', 'Hacksaw', 'Ridge', '(2016)'],\n",
       " ['195.', 'Salinui', 'chueok', '(2003)'],\n",
       " ['196.', 'Klaus', '(2019)'],\n",
       " ['197.', 'Relatos', 'salvajes', '(2014)'],\n",
       " ['198.', 'Det', 'sjunde', 'inseglet', '(1957)'],\n",
       " ['199.', 'Room', '(2015)'],\n",
       " ['200.', 'Mad', 'Max:', 'Fury', 'Road', '(2015)'],\n",
       " ['201.', 'How', 'to', 'Train', 'Your', 'Dragon', '(2010)'],\n",
       " ['202.', 'Mary', 'and', 'Max.', '(2009)'],\n",
       " ['203.', 'The', 'Big', 'Lebowski', '(1998)'],\n",
       " ['204.', 'Jaws', '(1975)'],\n",
       " ['205.', 'Monsters,', 'Inc.', '(2001)'],\n",
       " ['206.', 'Everything', 'Everywhere', 'All', 'at', 'Once', '(2022)'],\n",
       " ['207.', 'Tôkyô', 'monogatari', '(1953)'],\n",
       " ['208.', 'Dead', 'Poets', 'Society', '(1989)'],\n",
       " ['209.', 'La', 'passion', 'de', 'Jeanne', \"d'Arc\", '(1928)'],\n",
       " ['210.', 'Hotel', 'Rwanda', '(2004)'],\n",
       " ['211.', 'Ford', 'v', 'Ferrari', '(2019)'],\n",
       " ['212.', 'Rocky', '(1976)'],\n",
       " ['213.', 'Platoon', '(1986)'],\n",
       " ['214.', 'Pather', 'Panchali', '(1955)'],\n",
       " ['215.', 'Stand', 'by', 'Me', '(1986)'],\n",
       " ['216.', 'The', 'Terminator', '(1984)'],\n",
       " ['217.', 'Spotlight', '(2015)'],\n",
       " ['218.', 'Rush', '(2013)'],\n",
       " ['219.', 'Logan', '(2017)'],\n",
       " ['220.', 'Ratatouille', '(2007)'],\n",
       " ['221.', 'Network', '(1976)'],\n",
       " ['222.', 'Into', 'the', 'Wild', '(2007)'],\n",
       " ['223.', 'The', 'Wizard', 'of', 'Oz', '(1939)'],\n",
       " ['224.', 'Groundhog', 'Day', '(1993)'],\n",
       " ['225.', 'Before', 'Sunset', '(2004)'],\n",
       " ['226.', 'Jai', 'Bhim', '(2021)'],\n",
       " ['227.', 'The', 'Exorcist', '(1973)'],\n",
       " ['228.', 'The', 'Best', 'Years', 'of', 'Our', 'Lives', '(1946)'],\n",
       " ['229.', 'The', 'Incredibles', '(2004)'],\n",
       " ['230.', 'To', 'Be', 'or', 'Not', 'to', 'Be', '(1942)'],\n",
       " ['231.', 'La', 'battaglia', 'di', 'Algeri', '(1966)'],\n",
       " ['232.', 'The', 'Grapes', 'of', 'Wrath', '(1940)'],\n",
       " ['233.', 'Rebecca', '(1940)'],\n",
       " ['234.', 'Hachi:', 'A', \"Dog's\", 'Tale', '(2009)'],\n",
       " ['235.', 'Cool', 'Hand', 'Luke', '(1967)'],\n",
       " ['236.',\n",
       "  'Pirates',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Caribbean:',\n",
       "  'The',\n",
       "  'Curse',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Black',\n",
       "  'Pearl',\n",
       "  '(2003)'],\n",
       " ['237.', 'Amores', 'perros', '(2000)'],\n",
       " ['238.', 'La', 'haine', '(1995)'],\n",
       " ['239.', 'Babam', 've', 'Oglum', '(2005)'],\n",
       " ['240.', 'Les', 'quatre', 'cents', 'coups', '(1959)'],\n",
       " ['241.', 'Persona', '(1966)'],\n",
       " ['242.', 'It', 'Happened', 'One', 'Night', '(1934)'],\n",
       " ['243.', 'The', 'Sound', 'of', 'Music', '(1965)'],\n",
       " ['244.', 'Life', 'of', 'Brian', '(1979)'],\n",
       " ['245.', 'Ah-ga-ssi', '(2016)'],\n",
       " ['246.', 'Dersu', 'Uzala', '(1975)'],\n",
       " ['247.', 'Aladdin', '(1992)'],\n",
       " ['248.', 'Gandhi', '(1982)'],\n",
       " ['249.', 'The', 'Help', '(2011)'],\n",
       " ['250.', 'The', 'Iron', 'Giant', '(1999)']]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple movie titles\n",
    "titles = []\n",
    "\n",
    "for i in soup.find_all('td', class_=\"titleColumn\"):\n",
    "    titles.append(i.text.split())\n",
    "    \n",
    "    \n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ad54579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['9.2'], ['9.2'], ['9.0'], ['9.0'], ['8.9'], ['8.9'], ['8.9'], ['8.8'], ['8.8'], ['8.8'], ['8.8'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.7'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.6'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.5'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0']]\n"
     ]
    }
   ],
   "source": [
    "# scrap rating\n",
    "\n",
    "rating = []\n",
    "for i in soup.find_all('td', class_=\"ratingColumn imdbRating\"):\n",
    "    rating.append(i.text.split())\n",
    "    \n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2eddf20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(1994)', '(1972)', '(2008)', '(1974)', '(1957)', '(1993)', '(2003)', '(1994)', '(2001)', '(1966)', '(1994)', '(1999)', '(2010)', '(2002)', '(1980)', '(1999)', '(1990)', '(1975)', '(1995)', '(1954)', '(1946)', '(1991)', '(2002)', '(1998)', '(1997)', '(1999)', '(2014)', '(1977)', '(1991)', '(1985)', '(2001)', '(1960)', '(2002)', '(1994)', '(2019)', '(1994)', '(2000)', '(1998)', '(2006)', '(1995)', '(2006)', '(1942)', '(2014)', '(2011)', '(1988)', '(1962)', '(1936)', '(1968)', '(1954)', '(1979)', '(1931)', '(1988)', '(1979)', '(2000)', '(1981)', '(2012)', '(2008)', '(2006)', '(1950)', '(1957)', '(1980)', '(1940)', '(2018)', '(1957)', '(1986)', '(1999)', '(2018)', '(2022)', '(1964)', '(2012)', '(2003)', '(2019)', '(1984)', '(1995)', '(1995)', '(2017)', '(2009)', '(1981)', '(2019)', '(1997)', '(1984)', '(1997)', '(2016)', '(2000)', '(2010)', '(1952)', '(2009)', '(1963)', '(1983)', '(1968)', '(2004)', '(1992)', '(2018)', '(2012)', '(1962)', '(1941)', '(1931)', '(1959)', '(1985)', '(1958)', '(2001)', '(1971)', '(1944)', '(1960)', '(1987)', '(1952)', '(1983)', '(1962)', '(1973)', '(2020)', '(1995)', '(1976)', '(2009)', '(2010)', '(1997)', '(2011)', '(1927)', '(1988)', '(2000)', '(1948)', '(1989)', '(2019)', '(2007)', '(2004)', '(1965)', '(2005)', '(2016)', '(1921)', '(1959)', '(1950)', '(2020)', '(2018)', '(2013)', '(1961)', '(1985)', '(1995)', '(2021)', '(1992)', '(2006)', '(2007)', '(1998)', '(1999)', '(2001)', '(1975)', '(1961)', '(1948)', '(2010)', '(1993)', '(1950)', '(1963)', '(2003)', '(2007)', '(2003)', '(1980)', '(1974)', '(1980)', '(1982)', '(1939)', '(2005)', '(2015)', '(1998)', '(1954)', '(2009)', '(2004)', '(1957)', '(2017)', '(1996)', '(2011)', '(2008)', '(1996)', '(2013)', '(1988)', '(2004)', '(2002)', '(1925)', '(1982)', '(1997)', '(1954)', '(1949)', '(1995)', '(2013)', '(1959)', '(1957)', '(2011)', '(2014)', '(1926)', '(1978)', '(1993)', '(2014)', '(1953)', '(1975)', '(1939)', '(1924)', '(2016)', '(2003)', '(2019)', '(2014)', '(1957)', '(2015)', '(2015)', '(2010)', '(2009)', '(1998)', '(1975)', '(2001)', '(2022)', '(1953)', '(1989)', '(1928)', '(2004)', '(2019)', '(1976)', '(1986)', '(1955)', '(1986)', '(1984)', '(2015)', '(2013)', '(2017)', '(2007)', '(1976)', '(2007)', '(1939)', '(1993)', '(2004)', '(2021)', '(1973)', '(1946)', '(2004)', '(1942)', '(1966)', '(1940)', '(1940)', '(2009)', '(1967)', '(2003)', '(2000)', '(1995)', '(2005)', '(1959)', '(1966)', '(1934)', '(1965)', '(1979)', '(2016)', '(1975)', '(1992)', '(1982)', '(2011)', '(1999)']\n"
     ]
    }
   ],
   "source": [
    "# scraping movie year of release\n",
    "release_year = []\n",
    "for i in soup.find_all('span', class_=\"secondaryInfo\"):\n",
    "    release_year.append(i.text)\n",
    "    \n",
    "print(release_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee06a2",
   "metadata": {},
   "source": [
    "# MAKING DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "126bcd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250 250\n"
     ]
    }
   ],
   "source": [
    "# printing length\n",
    "\n",
    "print(len(titles), len(rating), len(release_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50d20172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3cdd9b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Movie_Names':titles, 'IMDB_Rating':rating, 'Year_Of_Release':release_year})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2222391d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Names</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Year_Of_Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1., The, Shawshank, Redemption, (1994)]</td>\n",
       "      <td>[9.2]</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2., The, Godfather, (1972)]</td>\n",
       "      <td>[9.2]</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3., The, Dark, Knight, (2008)]</td>\n",
       "      <td>[9.0]</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4., The, Godfather, Part, II, (1974)]</td>\n",
       "      <td>[9.0]</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5., 12, Angry, Men, (1957)]</td>\n",
       "      <td>[8.9]</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>[246., Dersu, Uzala, (1975)]</td>\n",
       "      <td>[8.0]</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>[247., Aladdin, (1992)]</td>\n",
       "      <td>[8.0]</td>\n",
       "      <td>(1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>[248., Gandhi, (1982)]</td>\n",
       "      <td>[8.0]</td>\n",
       "      <td>(1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>[249., The, Help, (2011)]</td>\n",
       "      <td>[8.0]</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>[250., The, Iron, Giant, (1999)]</td>\n",
       "      <td>[8.0]</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Movie_Names IMDB_Rating Year_Of_Release\n",
       "0    [1., The, Shawshank, Redemption, (1994)]       [9.2]          (1994)\n",
       "1                [2., The, Godfather, (1972)]       [9.2]          (1972)\n",
       "2             [3., The, Dark, Knight, (2008)]       [9.0]          (2008)\n",
       "3      [4., The, Godfather, Part, II, (1974)]       [9.0]          (1974)\n",
       "4                [5., 12, Angry, Men, (1957)]       [8.9]          (1957)\n",
       "..                                        ...         ...             ...\n",
       "245              [246., Dersu, Uzala, (1975)]       [8.0]          (1975)\n",
       "246                   [247., Aladdin, (1992)]       [8.0]          (1992)\n",
       "247                    [248., Gandhi, (1982)]       [8.0]          (1982)\n",
       "248                 [249., The, Help, (2011)]       [8.0]          (2011)\n",
       "249          [250., The, Iron, Giant, (1999)]       [8.0]          (1999)\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d597c9e6",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8fbc7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "ind_mvi_page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97f0ce48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_mvi_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ca5b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(ind_mvi_page.content)\n",
    "#print(soup1.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed4e16aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1.', 'Rocketry:', 'The', 'Nambi', 'Effect', '(2022)'], ['2.', 'Anbe', 'Sivam', '(2003)'], ['3.', 'Jai', 'Bhim', '(2021)'], ['4.', 'Golmaal', '(1979)'], ['5.', 'Nayakan', '(1987)'], ['6.', 'Pariyerum', 'Perumal', '(2018)'], ['7.', '777', 'Charlie', '(2022)'], ['8.', '3', 'Idiots', '(2009)'], ['9.', 'Apur', 'Sansar', '(1959)'], ['10.', 'Manichitrathazhu', '(1993)'], ['11.', 'Kumbalangi', 'Nights', '(2019)'], ['12.', 'Black', 'Friday', '(2004)'], ['13.', 'Soorarai', 'Pottru', '(2020)'], ['14.', '#Home', '(2021)'], ['15.', 'C/o', 'Kancharapalem', '(2018)'], ['16.', 'Taare', 'Zameen', 'Par', '(2007)'], ['17.', 'Kireedam', '(1989)'], ['18.', 'Dangal', '(2016)'], ['19.', 'Kaithi', '(2019)'], ['20.', 'Jersey', '(2019)'], ['21.', '96', '(2018)'], ['22.', 'Asuran', '(2019)'], ['23.', 'Thevar', 'Magan', '(1992)'], ['24.', 'Visaaranai', '(2015)'], ['25.', 'Sarpatta', 'Parambarai', '(2021)'], ['26.', 'Natsamrat', '(2016)'], ['27.', 'Thalapathi', '(1991)'], ['28.', 'Drishyam', '2', '(2021)'], ['29.', 'Pather', 'Panchali', '(1955)'], ['30.', 'Nadodikkattu', '(1987)'], ['31.', 'Sardar', 'Udham', '(2021)'], ['32.', 'Thani', 'Oruvan', '(2015)'], ['33.', 'Vada', 'Chennai', '(2018)'], ['34.', 'Jaane', 'Bhi', 'Do', 'Yaaro', '(1983)'], ['35.', 'Aparajito', '(1956)'], ['36.', 'Sita', 'Ramam', '(2022)'], ['37.', 'Khosla', 'Ka', 'Ghosla!', '(2006)'], ['38.', 'Drishyam', '(2013)'], ['39.', 'Peranbu', '(2018)'], ['40.', 'Anniyan', '(2005)'], ['41.', 'Ratsasan', '(2018)'], ['42.', 'Chupke', 'Chupke', '(1975)'], ['43.', 'Mahanati', '(2018)'], ['44.', 'Agent', 'Sai', 'Srinivasa', 'Athreya', '(2019)'], ['45.', 'Vikram', '(2022)'], ['46.', 'Premam', '(2015)'], ['47.', 'Bangalore', 'Days', '(2014)'], ['48.', 'Satya', '(1998)'], ['49.', 'Super', 'Deluxe', '(2019)'], ['50.', 'Devasuram', '(1993)'], ['51.', 'Gangs', 'of', 'Wasseypur', '(2012)'], ['52.', 'Bhaag', 'Milkha', 'Bhaag', '(2013)'], ['53.', 'Drishyam', '(2015)'], ['54.', 'Andhadhun', '(2018)'], ['55.', 'Aruvi', '(2016)'], ['56.', 'Chithram', '(1988)'], ['57.', 'Vikram', 'Vedha', '(2017)'], ['58.', 'Kannathil', 'Muthamittal', '(2002)'], ['59.', 'Guide', '(1965)'], ['60.', 'Iruvar', '(1997)'], ['61.', 'Tumbbad', '(2018)'], ['62.', 'Sairat', '(2016)'], ['63.', 'Shahid', '(2012)'], ['64.', 'Zindagi', 'Na', 'Milegi', 'Dobara', '(2011)'], ['65.', 'Paan', 'Singh', 'Tomar', '(2012)'], ['66.', 'Chhichhore', '(2019)'], ['67.', 'Mudhalvan', '(1999)'], ['68.', 'Spadikam', '(1995)'], ['69.', 'Pudhu', 'Pettai', '(2006)'], ['70.', 'Swades:', 'We,', 'the', 'People', '(2004)'], ['71.', 'Dhuruvangal', 'Pathinaaru', '(2016)'], ['72.', 'Chak', 'De!', 'India', '(2007)'], ['73.', 'Papanasam', '(2015)'], ['74.', 'Mandela', '(2021)'], ['75.', 'Uri:', 'The', 'Surgical', 'Strike', '(2019)'], ['76.', 'Black', '(2005)'], ['77.', 'Jo', 'Jeeta', 'Wohi', 'Sikandar', '(1992)'], ['78.', 'Pyaasa', '(1957)'], ['79.', 'Munna', 'Bhai', 'M.B.B.S.', '(2003)'], ['80.', 'Soodhu', 'Kavvum', '(2013)'], ['81.', 'Article', '15', '(2019)'], ['82.', 'Queen', '(2013)'], ['83.', 'Kaakkaa', 'Muttai', '(2014)'], ['84.', 'Lagaan:', 'Once', 'Upon', 'a', 'Time', 'in', 'India', '(2001)'], ['85.', 'Talvar', '(2015)'], ['86.', 'PK', '(2014)'], ['87.', 'OMG:', 'Oh', 'My', 'God!', '(2012)'], ['88.', 'Jigarthanda', '(2014)'], ['89.', 'Hera', 'Pheri', '(2000)'], ['90.', 'Sarfarosh', '(1999)'], ['91.', 'Udaan', '(2010)'], ['92.', 'Theeran', 'Adhigaaram', 'Ondru', '(2017)'], ['93.', 'Barfi!', '(2012)'], ['94.', 'Sholay', '(1975)'], ['95.', 'Ustad', 'Hotel', '(2012)'], ['96.', 'The', 'Legend', 'of', 'Bhagat', 'Singh', '(2002)'], ['97.', 'Virumandi', '(2004)'], ['98.', 'Baahubali', '2:', 'The', 'Conclusion', '(2017)'], ['99.', 'Angoor', '(1982)'], ['100.', 'Rang', 'De', 'Basanti', '(2006)'], ['101.', 'Baasha', '(1995)'], ['102.', 'Jana', 'Gana', 'Mana', '(2022)'], ['103.', 'Maheshinte', 'Prathikaaram', '(2016)'], ['104.', 'Masaan', '(2015)'], ['105.', 'Kahaani', '(2012)'], ['106.', 'Shershaah', '(2021)'], ['107.', 'Dil', 'Chahta', 'Hai', '(2001)'], ['108.', 'Kaun', 'Pravin', 'Tambe?', '(2022)'], ['109.', 'A', 'Wednesday', '(2008)'], ['110.', 'Roja', '(1992)'], ['111.', 'Pithamagan', '(2003)'], ['112.', 'Iqbal', '(2005)'], ['113.', 'Pink', '(2016)'], ['114.', 'Lage', 'Raho', 'Munna', 'Bhai', '(2006)'], ['115.', 'Nil', 'Battey', 'Sannata', '(2015)'], ['116.', 'Anand', '(1971)'], ['117.', 'Charulata', '(1964)'], ['118.', 'Lucia', '(2013)'], ['119.', 'Alai', 'Payuthey', '(2000)'], ['120.', 'Section', '375', '(2019)'], ['121.', 'Oru', 'Vadakkan', 'Veeragatha', '(1989)'], ['122.', 'Omkara', '(2006)'], ['123.', 'Bajrangi', 'Bhaijaan', '(2015)'], ['124.', 'Bombay', '(1995)'], ['125.', 'Bommarillu', '(2006)'], ['126.', 'K.G.F:', 'Chapter', '1', '(2018)'], ['127.', 'Indian', '(1996)'], ['128.', 'The', 'Great', 'Indian', 'Kitchen', '(2021)'], ['129.', 'K.G.F:', 'Chapter', '2', '(2022)'], ['130.', 'Rangasthalam', '(2018)'], ['131.', 'Haider', '(2014)'], ['132.', 'Mughal-E-Azam', '(1960)'], ['133.', 'Dilwale', 'Dulhania', 'Le', 'Jayenge', '(1995)'], ['134.', 'Maanaadu', '(2021)'], ['135.', 'Athadu', '(2005)'], ['136.', 'Maqbool', '(2003)'], ['137.', 'Andaz', 'Apna', 'Apna', '(1994)'], ['138.', 'Special', 'Chabbis', '(2013)'], ['139.', 'Thadam', '(2019)'], ['140.', 'Vaaranam', 'Aayiram', '(2008)'], ['141.', 'Android', 'Kunjappan', 'Version', '5.25', '(2019)'], ['142.', 'Padayappa', '(1999)'], ['143.', 'Pelli', 'Choopulu', '(2016)'], ['144.', 'Gulaal', '(2009)'], ['145.', 'Ulidavaru', 'Kandanthe', '(2014)'], ['146.', 'Naduvula', 'Konjam', 'Pakkatha', 'Kaanom', '(2012)'], ['147.', 'Deewaar', '(1975)'], ['148.', 'Badhaai', 'ho', '(2018)'], ['149.', 'Vaastav:', 'The', 'Reality', '(1999)'], ['150.', 'Ugly', '(2013)'], ['151.', 'Kshanam', '(2016)'], ['152.', 'Company', '(2002)'], ['153.', 'Evaru', '(2019)'], ['154.', 'Gully', 'Boy', '(2019)'], ['155.', 'Padosan', '(1968)'], ['156.', 'Major', '(2022)'], ['157.', 'Aadukalam', '(2011)'], ['158.', 'Maanagaram', '(2017)'], ['159.', 'Nayattu', '(2021)'], ['160.', 'Thondimuthalum', 'Dhriksakshiyum', '(2017)'], ['161.', 'Dev.D', '(2009)'], ['162.', 'My', 'Name', 'Is', 'Khan', '(2010)'], ['163.', 'Take', 'Off', '(2017)'], ['164.', 'Pranchiyettan', 'and', 'the', 'Saint', '(2010)'], ['165.', 'Baishe', 'Srabon', '(2011)'], ['166.', 'Kal', 'Ho', 'Naa', 'Ho', '(2003)'], ['167.', 'Ayyappanum', 'Koshiyum', '(2020)'], ['168.', 'Dil', 'Bechara', '(2020)'], ['169.', 'Jab', 'We', 'Met', '(2007)'], ['170.', 'Manjhi:', 'The', 'Mountain', 'Man', '(2015)'], ['171.', 'Mukkabaaz', '(2017)'], ['172.', 'Super', '30', '(2019)'], ['173.', 'Deiva', 'Thirumagal', '(2011)'], ['174.', 'Arjun', 'Reddy', '(2017)'], ['175.', 'Karnan', '(2021)'], ['176.', 'Border', '(1997)'], ['177.', 'Ship', 'of', 'Theseus', '(2012)'], ['178.', 'Charlie', '(2015)'], ['179.', 'Vedam', '(2010)'], ['180.', 'Bãhubali:', 'The', 'Beginning', '(2015)'], ['181.', 'Padman', '(2018)'], ['182.', 'Salaam', 'Bombay!', '(1988)'], ['183.', 'Ankhon', 'Dekhi', '(2013)'], ['184.', 'Jalsaghar', '(1958)'], ['185.', 'Baby', '(2015)'], ['186.', 'RRR', '(Rise', 'Roar', 'Revolt)', '(2022)'], ['187.', 'M.S.', 'Dhoni:', 'The', 'Untold', 'Story', '(2016)'], ['188.', 'Vinnaithaandi', 'Varuvaayaa', '(2010)'], ['189.', 'Malik', '(2021)'], ['190.', 'Kirik', 'Party', '(2016)'], ['191.', 'Pizza', '(2012)'], ['192.', 'The', 'Tashkent', 'Files', '(2019)'], ['193.', 'Memories', '(2013)'], ['194.', 'Hindi', 'Medium', '(2017)'], ['195.', 'Hridayam', '(2022)'], ['196.', 'Lakshya', '(2004)'], ['197.', 'English', 'Vinglish', '(2012)'], ['198.', 'Dor', '(2006)'], ['199.', 'Johnny', 'Gaddaar', '(2007)'], ['200.', 'Airlift', '(2016)'], ['201.', 'Hey', 'Ram', '(2000)'], ['202.', 'Joseph', '(2018)'], ['203.', 'Kaakha..Kaakha:', 'The', 'Police', '(2003)'], ['204.', 'Anjaam', 'Pathiraa', '(2020)'], ['205.', 'Gangaajal', '(2003)'], ['206.', 'Karthikeya', '2', '(2022)'], ['207.', 'Vettaiyaadu', 'Vilaiyaadu', '(2006)'], ['208.', 'Okkadu', '(2003)'], ['209.', 'Mumbai', 'Police', '(2013)'], ['210.', 'The', 'Lunchbox', '(2013)'], ['211.', 'Pokiri', '(2006)'], ['212.', 'Ab', 'Tak', 'Chhappan', '(2004)'], ['213.', 'Thuppakki', '(2012)'], ['214.', 'Oopiri', '(2016)'], ['215.', 'Angamaly', 'Diaries', '(2017)'], ['216.', 'Unnaipol', 'Oruvan', '(2009)'], ['217.', 'Manam', '(2014)'], ['218.', 'RangiTaranga', '(2015)'], ['219.', 'Ghilli', '(2004)'], ['220.', 'Vicky', 'Donor', '(2012)'], ['221.', 'Secret', 'Superstar', '(2017)'], ['222.', 'Mother', 'India', '(1957)'], ['223.', 'Veer-Zaara', '(2004)'], ['224.', 'Kaththi', '(2014)'], ['225.', 'Mimi', '(2021)'], ['226.', 'Sonchiriya', '(2019)'], ['227.', 'Dia', '(2020)'], ['228.', 'Oru', 'CBI', 'Diary', 'Kurippu', '(1988)'], ['229.', 'Stanley', 'Ka', 'Dabba', '(2011)'], ['230.', 'Rock', 'On!!', '(2008)'], ['231.', 'Mr.', 'India', '(1987)'], ['232.', 'Nayak:', 'The', 'Real', 'Hero', '(2001)'], ['233.', 'Udta', 'Punjab', '(2016)'], ['234.', 'Thulladha', 'Manamum', 'Thullum', '(1999)'], ['235.', 'Happy', 'Days', '(2007)'], ['236.', 'Minnal', 'Murali', '(2021)'], ['237.', 'Aayirathil', 'Oruvan', '(2010)'], ['238.', 'Badla', '(2019)'], ['239.', 'Raazi', '(2018)'], ['240.', 'Dasvidaniya', '(2008)'], ['241.', 'Poove', 'Unakkaga', '(1996)'], ['242.', 'Kai', 'po', 'che!', '(2013)'], ['243.', 'Goodachari', '(2018)'], ['244.', 'Joji', '(2021)'], ['245.', 'Ko', '(2011)'], ['246.', 'Don', '(1978)'], ['247.', 'Ennu', 'Ninte', 'Moideen', '(2015)'], ['248.', 'Velaiilla', 'Pattadhari', '(2014)'], ['249.', 'Aligarh', '(2015)'], ['250.', '24', '(2016)']]\n"
     ]
    }
   ],
   "source": [
    "# multiple movie titles\n",
    "\n",
    "movie_titles = []\n",
    "\n",
    "for i in soup1.find_all('td', class_=\"titleColumn\"):\n",
    "    movie_titles.append(i.text.split())\n",
    "    \n",
    "    \n",
    "print(movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4f41b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['8.5'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.4'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.3'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.2'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.1'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['8.0'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.9'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.8'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.7'], ['7.6'], ['7.6'], ['7.6'], ['7.6']]\n"
     ]
    }
   ],
   "source": [
    "# scrap rating\n",
    "\n",
    "mvi_rating = []\n",
    "for i in soup1.find_all('td', class_=\"ratingColumn imdbRating\"):\n",
    "    mvi_rating.append(i.text.split())\n",
    "    \n",
    "print(mvi_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5825df46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(2022)', '(2003)', '(2021)', '(1979)', '(1987)', '(2018)', '(2022)', '(2009)', '(1959)', '(1993)', '(2019)', '(2004)', '(2020)', '(2021)', '(2018)', '(2007)', '(1989)', '(2016)', '(2019)', '(2019)', '(2018)', '(2019)', '(1992)', '(2015)', '(2021)', '(2016)', '(1991)', '(2021)', '(1955)', '(1987)', '(2021)', '(2015)', '(2018)', '(1983)', '(1956)', '(2022)', '(2006)', '(2013)', '(2018)', '(2005)', '(2018)', '(1975)', '(2018)', '(2019)', '(2022)', '(2015)', '(2014)', '(1998)', '(2019)', '(1993)', '(2012)', '(2013)', '(2015)', '(2018)', '(2016)', '(1988)', '(2017)', '(2002)', '(1965)', '(1997)', '(2018)', '(2016)', '(2012)', '(2011)', '(2012)', '(2019)', '(1999)', '(1995)', '(2006)', '(2004)', '(2016)', '(2007)', '(2015)', '(2021)', '(2019)', '(2005)', '(1992)', '(1957)', '(2003)', '(2013)', '(2019)', '(2013)', '(2014)', '(2001)', '(2015)', '(2014)', '(2012)', '(2014)', '(2000)', '(1999)', '(2010)', '(2017)', '(2012)', '(1975)', '(2012)', '(2002)', '(2004)', '(2017)', '(1982)', '(2006)', '(1995)', '(2022)', '(2016)', '(2015)', '(2012)', '(2021)', '(2001)', '(2022)', '(2008)', '(1992)', '(2003)', '(2005)', '(2016)', '(2006)', '(2015)', '(1971)', '(1964)', '(2013)', '(2000)', '(2019)', '(1989)', '(2006)', '(2015)', '(1995)', '(2006)', '(2018)', '(1996)', '(2021)', '(2022)', '(2018)', '(2014)', '(1960)', '(1995)', '(2021)', '(2005)', '(2003)', '(1994)', '(2013)', '(2019)', '(2008)', '(2019)', '(1999)', '(2016)', '(2009)', '(2014)', '(2012)', '(1975)', '(2018)', '(1999)', '(2013)', '(2016)', '(2002)', '(2019)', '(2019)', '(1968)', '(2022)', '(2011)', '(2017)', '(2021)', '(2017)', '(2009)', '(2010)', '(2017)', '(2010)', '(2011)', '(2003)', '(2020)', '(2020)', '(2007)', '(2015)', '(2017)', '(2019)', '(2011)', '(2017)', '(2021)', '(1997)', '(2012)', '(2015)', '(2010)', '(2015)', '(2018)', '(1988)', '(2013)', '(1958)', '(2015)', '(2022)', '(2016)', '(2010)', '(2021)', '(2016)', '(2012)', '(2019)', '(2013)', '(2017)', '(2022)', '(2004)', '(2012)', '(2006)', '(2007)', '(2016)', '(2000)', '(2018)', '(2003)', '(2020)', '(2003)', '(2022)', '(2006)', '(2003)', '(2013)', '(2013)', '(2006)', '(2004)', '(2012)', '(2016)', '(2017)', '(2009)', '(2014)', '(2015)', '(2004)', '(2012)', '(2017)', '(1957)', '(2004)', '(2014)', '(2021)', '(2019)', '(2020)', '(1988)', '(2011)', '(2008)', '(1987)', '(2001)', '(2016)', '(1999)', '(2007)', '(2021)', '(2010)', '(2019)', '(2018)', '(2008)', '(1996)', '(2013)', '(2018)', '(2021)', '(2011)', '(1978)', '(2015)', '(2014)', '(2015)', '(2016)']\n"
     ]
    }
   ],
   "source": [
    "# scraping movie year of release\n",
    "\n",
    "mvi_release_year = []\n",
    "for i in soup1.find_all('span', class_=\"secondaryInfo\"):\n",
    "    mvi_release_year.append(i.text)\n",
    "    \n",
    "print(mvi_release_year)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a027719c",
   "metadata": {},
   "source": [
    "# MAKING DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ec80a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250 250\n"
     ]
    }
   ],
   "source": [
    "# printing length\n",
    "\n",
    "print(len(movie_titles), len(mvi_rating), len(mvi_release_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "193fd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe to create table\n",
    "\n",
    "df1 = pd.DataFrame({'Movie_Names':movie_titles, 'IMDB_Rating':mvi_rating, 'Year_Of_Release':mvi_release_year})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "008a783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Names</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Year_Of_Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1., Rocketry:, The, Nambi, Effect, (2022)]</td>\n",
       "      <td>[8.5]</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2., Anbe, Sivam, (2003)]</td>\n",
       "      <td>[8.4]</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3., Jai, Bhim, (2021)]</td>\n",
       "      <td>[8.4]</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4., Golmaal, (1979)]</td>\n",
       "      <td>[8.4]</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5., Nayakan, (1987)]</td>\n",
       "      <td>[8.4]</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>[246., Don, (1978)]</td>\n",
       "      <td>[7.7]</td>\n",
       "      <td>(1978)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>[247., Ennu, Ninte, Moideen, (2015)]</td>\n",
       "      <td>[7.6]</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>[248., Velaiilla, Pattadhari, (2014)]</td>\n",
       "      <td>[7.6]</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>[249., Aligarh, (2015)]</td>\n",
       "      <td>[7.6]</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>[250., 24, (2016)]</td>\n",
       "      <td>[7.6]</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Movie_Names IMDB_Rating Year_Of_Release\n",
       "0    [1., Rocketry:, The, Nambi, Effect, (2022)]       [8.5]          (2022)\n",
       "1                      [2., Anbe, Sivam, (2003)]       [8.4]          (2003)\n",
       "2                        [3., Jai, Bhim, (2021)]       [8.4]          (2021)\n",
       "3                          [4., Golmaal, (1979)]       [8.4]          (1979)\n",
       "4                          [5., Nayakan, (1987)]       [8.4]          (1987)\n",
       "..                                           ...         ...             ...\n",
       "245                          [246., Don, (1978)]       [7.7]          (1978)\n",
       "246         [247., Ennu, Ninte, Moideen, (2015)]       [7.6]          (2015)\n",
       "247        [248., Velaiilla, Pattadhari, (2014)]       [7.6]          (2014)\n",
       "248                      [249., Aligarh, (2015)]       [7.6]          (2015)\n",
       "249                           [250., 24, (2016)]       [7.6]          (2016)\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b410d",
   "metadata": {},
   "source": [
    "# 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office)from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3bbcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "former_pres = requests.get('https://presidentofindia.nic.in/former-presidents.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e28bc599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "former_pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac7d5f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(former_pres.content)\n",
    "#print(soup2.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc490948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shri Ram Nath Kovind (birth - 1945)\n",
      "Shri Pranab Mukherjee (1935-2020)\n",
      "Smt Pratibha Devisingh Patil (birth - 1934)\n",
      "DR. A.P.J. Abdul Kalam (1931-2015)\n",
      "Shri K. R. Narayanan (1920 - 2005)\n",
      "Dr Shankar Dayal Sharma (1918-1999)\n",
      "Shri R Venkataraman (1910-2009)\n",
      "Giani Zail Singh (1916-1994)\n",
      "Shri Neelam Sanjiva Reddy (1913-1996)\n",
      "Dr. Fakhruddin Ali Ahmed (1905-1977)\n",
      "Shri Varahagiri Venkata Giri (1894-1980)\n",
      "Dr. Zakir Husain (1897-1969)\n",
      "Dr. Sarvepalli Radhakrishnan (1888-1975)\n",
      "Dr. Rajendra Prasad (1884-1963) \n"
     ]
    }
   ],
   "source": [
    "# scrap multiple names of presidents \n",
    "\n",
    "pres_names = soup2.find_all(['h3'])\n",
    "\n",
    "for i in pres_names:\n",
    "    print(i.get_text())  \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "023bab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term of Office: 25 July, 2017 to 25 July, 2022 \n",
      "https://ramnathkovind.nic.in\n",
      "Term of Office: 25 July, 2012 to 25 July, 2017 \n",
      "http://pranabmukherjee.nic.in\n",
      "Term of Office: 25 July, 2007 to 25 July, 2012 \n",
      "http://pratibhapatil.nic.in\n",
      "Term of Office: 25 July, 2002 to 25 July, 2007 \n",
      "http://abdulkalam.nic.in\n",
      "Term of Office: 25 July, 1997 to 25 July, 2002 \n",
      "Term of Office: 25 July, 1992 to 25 July, 1997 \n",
      "Term of Office: 25 July, 1987 to 25 July, 1992 \n",
      "Term of Office: 25 July, 1982 to 25 July, 1987 \n",
      "Term of Office: 25 July, 1977 to 25 July, 1982 \n",
      "Term of Office: 24 August, 1974 to 11 February, 1977\n",
      "Term of Office: 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974\n",
      "Term of Office: 13 May, 1967 to 3 May, 1969\n",
      "Term of Office: 13 May, 1962 to 13 May, 1967\n",
      "Term of Office: 26 January, 1950 to 13 May, 1962\n",
      "Copyright © 2022 The Rashtrapati Bhavan.\n",
      "Page last updated on: 22-July-2022 15:58 PM\n",
      "\n",
      "\r\n",
      " Website hosted by National Informatics Centre. Website Content provided by the President's Secretariat.\n"
     ]
    }
   ],
   "source": [
    "# scrap presidents office term\n",
    "\n",
    "offc_terms = soup2.find_all(['p'])\n",
    "\n",
    "for i in offc_terms:\n",
    "    print(i.get_text())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3a6d91",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc0472",
   "metadata": {},
   "source": [
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55e88e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "icc = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df3cf081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(icc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "11ae9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup3 = BeautifulSoup(icc.content)\n",
    "#print(soup3.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e8ec35b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['New', 'Zealand', 'NZ'],\n",
       " ['India', 'IND'],\n",
       " ['Pakistan', 'PAK'],\n",
       " ['Australia', 'AUS'],\n",
       " ['South', 'Africa', 'SA'],\n",
       " ['Bangladesh', 'BAN'],\n",
       " ['Sri', 'Lanka', 'SL'],\n",
       " ['West', 'Indies', 'WI'],\n",
       " ['Afghanistan', 'AFG'],\n",
       " ['Ireland', 'IRE'],\n",
       " ['Scotland', 'SCO'],\n",
       " ['Zimbabwe', 'ZIM'],\n",
       " ['Namibia', 'NAM'],\n",
       " ['Netherlands', 'NED'],\n",
       " ['UAE', 'UAE'],\n",
       " ['Oman', 'OMA'],\n",
       " ['United', 'States', 'USA'],\n",
       " ['Nepal', 'NEP'],\n",
       " ['Papua', 'New', 'Guinea', 'PNG']]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci team names\n",
    "\n",
    "team_names = []\n",
    "\n",
    "for i in soup3.find_all('td', class_=\"table-body__cell rankings-table__team\"):\n",
    "    team_names.append(i.text.split())\n",
    "    \n",
    "team_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a8e53fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22', '2,508', '31', '3,447', '22', '2,354', '29', '3,071', '21', '2,111', '30', '2,753', '29', '2,658', '41', '2,902', '18', '1,238', '23', '1,214', '27', '1,254', '26', '1,098', '19', '642', '21', '673', '22', '697', '30', '919', '27', '641', '22', '331', '26', '209']\n"
     ]
    }
   ],
   "source": [
    " # scrap match recording and points\n",
    "    match_rec = []\n",
    "\n",
    "for i in soup3.find_all('td', class_=\"table-body__cell u-center-text\"):\n",
    "\n",
    "    match_rec.append(i.text)\n",
    "    \n",
    "print(match_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f611b7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['114', '111', '107', '106', '101', '92', '92', '71', '69', '53', '46', '42', '34', '32', '32', '31', '24', '15', '8']\n"
     ]
    }
   ],
   "source": [
    " match_rating = []\n",
    "    \n",
    "for i in soup3.find_all('td', class_=\"table-body__cell u-text-right rating\"):\n",
    "    \n",
    "    match_rating.append(i.text)\n",
    "    \n",
    "print(match_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67737bf0",
   "metadata": {},
   "source": [
    "b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd0f8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "icc_player = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0a484fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b45309eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup4 = BeautifulSoup(icc_player.content)\n",
    "#print(soup4.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c116c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rassie', 'van', 'der', 'Dussen'],\n",
       " ['Quinton', 'de', 'Kock'],\n",
       " ['Imam-ul-Haq'],\n",
       " ['Virat', 'Kohli'],\n",
       " ['Rohit', 'Sharma'],\n",
       " ['Jonny', 'Bairstow'],\n",
       " ['David', 'Warner'],\n",
       " ['Ross', 'Taylor'],\n",
       " ['Steve', 'Smith'],\n",
       " ['Josh', 'Hazlewood'],\n",
       " ['Mujeeb', 'Ur', 'Rahman'],\n",
       " ['Jasprit', 'Bumrah'],\n",
       " ['Shaheen', 'Afridi'],\n",
       " ['Mohammad', 'Nabi'],\n",
       " ['Mehedi', 'Hasan'],\n",
       " ['Matt', 'Henry'],\n",
       " ['Mitchell', 'Starc'],\n",
       " ['Rashid', 'Khan'],\n",
       " ['Mohammad', 'Nabi'],\n",
       " ['Rashid', 'Khan'],\n",
       " ['Mitchell', 'Santner'],\n",
       " ['Sikandar', 'Raza'],\n",
       " ['Zeeshan', 'Maqsood'],\n",
       " ['Mehedi', 'Hasan'],\n",
       " ['Chris', 'Woakes'],\n",
       " ['Glenn', 'Maxwell'],\n",
       " ['Imad', 'Wasim'],\n",
       " ['Rassie', 'van', 'der', 'Dussen'],\n",
       " ['Quinton', 'de', 'Kock'],\n",
       " ['Imam-ul-Haq'],\n",
       " ['Virat', 'Kohli'],\n",
       " ['Rohit', 'Sharma'],\n",
       " ['Jonny', 'Bairstow'],\n",
       " ['David', 'Warner'],\n",
       " ['Ross', 'Taylor'],\n",
       " ['Steve', 'Smith'],\n",
       " ['Josh', 'Hazlewood'],\n",
       " ['Mujeeb', 'Ur', 'Rahman'],\n",
       " ['Jasprit', 'Bumrah'],\n",
       " ['Shaheen', 'Afridi'],\n",
       " ['Mohammad', 'Nabi'],\n",
       " ['Mehedi', 'Hasan'],\n",
       " ['Matt', 'Henry'],\n",
       " ['Mitchell', 'Starc'],\n",
       " ['Rashid', 'Khan'],\n",
       " ['Mohammad', 'Nabi'],\n",
       " ['Rashid', 'Khan'],\n",
       " ['Mitchell', 'Santner'],\n",
       " ['Sikandar', 'Raza'],\n",
       " ['Zeeshan', 'Maqsood'],\n",
       " ['Mehedi', 'Hasan'],\n",
       " ['Chris', 'Woakes'],\n",
       " ['Glenn', 'Maxwell'],\n",
       " ['Imad', 'Wasim']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci players names\n",
    "\n",
    "player_names = []\n",
    "\n",
    "for i in soup4.find_all('td', class_=\"table-body__cell name\"):\n",
    "    player_names.append(i.text.split())\n",
    "    \n",
    "player_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c455637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SA'],\n",
       " ['SA'],\n",
       " ['PAK'],\n",
       " ['IND'],\n",
       " ['IND'],\n",
       " ['ENG'],\n",
       " ['AUS'],\n",
       " ['NZ'],\n",
       " ['AUS'],\n",
       " ['AUS'],\n",
       " ['AFG'],\n",
       " ['IND'],\n",
       " ['PAK'],\n",
       " ['AFG'],\n",
       " ['BAN'],\n",
       " ['NZ'],\n",
       " ['AUS'],\n",
       " ['AFG'],\n",
       " ['AFG'],\n",
       " ['AFG'],\n",
       " ['NZ'],\n",
       " ['ZIM'],\n",
       " ['OMA'],\n",
       " ['BAN'],\n",
       " ['ENG'],\n",
       " ['AUS'],\n",
       " ['PAK'],\n",
       " ['SA'],\n",
       " ['SA'],\n",
       " ['PAK'],\n",
       " ['IND'],\n",
       " ['IND'],\n",
       " ['ENG'],\n",
       " ['AUS'],\n",
       " ['NZ'],\n",
       " ['AUS'],\n",
       " ['AUS'],\n",
       " ['AFG'],\n",
       " ['IND'],\n",
       " ['PAK'],\n",
       " ['AFG'],\n",
       " ['BAN'],\n",
       " ['NZ'],\n",
       " ['AUS'],\n",
       " ['AFG'],\n",
       " ['AFG'],\n",
       " ['AFG'],\n",
       " ['NZ'],\n",
       " ['ZIM'],\n",
       " ['OMA'],\n",
       " ['BAN'],\n",
       " ['ENG'],\n",
       " ['AUS'],\n",
       " ['PAK']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci players country names\n",
    "\n",
    "country_names = []\n",
    "\n",
    "for i in soup4.find_all('td', class_=\"table-body__cell nationality-logo\"):\n",
    "    country_names.append(i.text.split())\n",
    "    \n",
    "country_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9df9cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['789'],\n",
       " ['784'],\n",
       " ['779'],\n",
       " ['744'],\n",
       " ['740'],\n",
       " ['732'],\n",
       " ['725'],\n",
       " ['701'],\n",
       " ['697'],\n",
       " ['718'],\n",
       " ['676'],\n",
       " ['662'],\n",
       " ['661'],\n",
       " ['657'],\n",
       " ['655'],\n",
       " ['654'],\n",
       " ['653'],\n",
       " ['651'],\n",
       " ['325'],\n",
       " ['290'],\n",
       " ['275'],\n",
       " ['261'],\n",
       " ['238'],\n",
       " ['238'],\n",
       " ['235'],\n",
       " ['227'],\n",
       " ['220'],\n",
       " ['789'],\n",
       " ['784'],\n",
       " ['779'],\n",
       " ['744'],\n",
       " ['740'],\n",
       " ['732'],\n",
       " ['725'],\n",
       " ['701'],\n",
       " ['697'],\n",
       " ['718'],\n",
       " ['676'],\n",
       " ['662'],\n",
       " ['661'],\n",
       " ['657'],\n",
       " ['655'],\n",
       " ['654'],\n",
       " ['653'],\n",
       " ['651'],\n",
       " ['325'],\n",
       " ['290'],\n",
       " ['275'],\n",
       " ['261'],\n",
       " ['238'],\n",
       " ['238'],\n",
       " ['235'],\n",
       " ['227'],\n",
       " ['220']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci Batsman rating\n",
    "\n",
    "batsman_rating = []\n",
    "\n",
    "for i in soup4.find_all('td', class_=\"table-body__cell u-text-right rating\"):\n",
    "    batsman_rating.append(i.text.split())\n",
    "    \n",
    "batsman_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5ae46",
   "metadata": {},
   "source": [
    "Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f87c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e49a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe of batsman to create table\n",
    "\n",
    "df_bat = pd.DataFrame({'BATSMAN':player_names, 'COUNTRY':country_names, 'ICC_RATING':batsman_rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "163a0fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BATSMAN</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>ICC_RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Rassie, van, der, Dussen]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[789]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Quinton, de, Kock]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[784]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Imam-ul-Haq]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[779]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Virat, Kohli]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Rohit, Sharma]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[740]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Jonny, Bairstow]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[732]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[David, Warner]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[725]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Ross, Taylor]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[701]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Steve, Smith]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Josh, Hazlewood]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Mujeeb, Ur, Rahman]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Jasprit, Bumrah]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[662]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Shaheen, Afridi]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[661]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Mohammad, Nabi]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[657]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[Mehedi, Hasan]</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>[655]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[Matt, Henry]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[654]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[Mitchell, Starc]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[653]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[Rashid, Khan]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[651]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[Mohammad, Nabi]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[Rashid, Khan]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[290]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[Mitchell, Santner]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[275]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[Sikandar, Raza]</td>\n",
       "      <td>[ZIM]</td>\n",
       "      <td>[261]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[Zeeshan, Maqsood]</td>\n",
       "      <td>[OMA]</td>\n",
       "      <td>[238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[Mehedi, Hasan]</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>[238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[Chris, Woakes]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[Glenn, Maxwell]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[227]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[Imad, Wasim]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[220]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[Rassie, van, der, Dussen]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[789]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[Quinton, de, Kock]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[784]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[Imam-ul-Haq]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[779]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[Virat, Kohli]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[Rohit, Sharma]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[740]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[Jonny, Bairstow]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[732]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[David, Warner]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[725]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[Ross, Taylor]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[701]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[Steve, Smith]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[Josh, Hazlewood]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[Mujeeb, Ur, Rahman]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[Jasprit, Bumrah]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[662]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[Shaheen, Afridi]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[661]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[Mohammad, Nabi]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[657]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[Mehedi, Hasan]</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>[655]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[Matt, Henry]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[654]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[Mitchell, Starc]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[653]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[Rashid, Khan]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[651]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[Mohammad, Nabi]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[Rashid, Khan]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[290]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[Mitchell, Santner]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[275]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[Sikandar, Raza]</td>\n",
       "      <td>[ZIM]</td>\n",
       "      <td>[261]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[Zeeshan, Maqsood]</td>\n",
       "      <td>[OMA]</td>\n",
       "      <td>[238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[Mehedi, Hasan]</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>[238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[Chris, Woakes]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[Glenn, Maxwell]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[227]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[Imad, Wasim]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[220]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       BATSMAN COUNTRY ICC_RATING\n",
       "0   [Rassie, van, der, Dussen]    [SA]      [789]\n",
       "1          [Quinton, de, Kock]    [SA]      [784]\n",
       "2                [Imam-ul-Haq]   [PAK]      [779]\n",
       "3               [Virat, Kohli]   [IND]      [744]\n",
       "4              [Rohit, Sharma]   [IND]      [740]\n",
       "5            [Jonny, Bairstow]   [ENG]      [732]\n",
       "6              [David, Warner]   [AUS]      [725]\n",
       "7               [Ross, Taylor]    [NZ]      [701]\n",
       "8               [Steve, Smith]   [AUS]      [697]\n",
       "9            [Josh, Hazlewood]   [AUS]      [718]\n",
       "10        [Mujeeb, Ur, Rahman]   [AFG]      [676]\n",
       "11           [Jasprit, Bumrah]   [IND]      [662]\n",
       "12           [Shaheen, Afridi]   [PAK]      [661]\n",
       "13            [Mohammad, Nabi]   [AFG]      [657]\n",
       "14             [Mehedi, Hasan]   [BAN]      [655]\n",
       "15               [Matt, Henry]    [NZ]      [654]\n",
       "16           [Mitchell, Starc]   [AUS]      [653]\n",
       "17              [Rashid, Khan]   [AFG]      [651]\n",
       "18            [Mohammad, Nabi]   [AFG]      [325]\n",
       "19              [Rashid, Khan]   [AFG]      [290]\n",
       "20         [Mitchell, Santner]    [NZ]      [275]\n",
       "21            [Sikandar, Raza]   [ZIM]      [261]\n",
       "22          [Zeeshan, Maqsood]   [OMA]      [238]\n",
       "23             [Mehedi, Hasan]   [BAN]      [238]\n",
       "24             [Chris, Woakes]   [ENG]      [235]\n",
       "25            [Glenn, Maxwell]   [AUS]      [227]\n",
       "26               [Imad, Wasim]   [PAK]      [220]\n",
       "27  [Rassie, van, der, Dussen]    [SA]      [789]\n",
       "28         [Quinton, de, Kock]    [SA]      [784]\n",
       "29               [Imam-ul-Haq]   [PAK]      [779]\n",
       "30              [Virat, Kohli]   [IND]      [744]\n",
       "31             [Rohit, Sharma]   [IND]      [740]\n",
       "32           [Jonny, Bairstow]   [ENG]      [732]\n",
       "33             [David, Warner]   [AUS]      [725]\n",
       "34              [Ross, Taylor]    [NZ]      [701]\n",
       "35              [Steve, Smith]   [AUS]      [697]\n",
       "36           [Josh, Hazlewood]   [AUS]      [718]\n",
       "37        [Mujeeb, Ur, Rahman]   [AFG]      [676]\n",
       "38           [Jasprit, Bumrah]   [IND]      [662]\n",
       "39           [Shaheen, Afridi]   [PAK]      [661]\n",
       "40            [Mohammad, Nabi]   [AFG]      [657]\n",
       "41             [Mehedi, Hasan]   [BAN]      [655]\n",
       "42               [Matt, Henry]    [NZ]      [654]\n",
       "43           [Mitchell, Starc]   [AUS]      [653]\n",
       "44              [Rashid, Khan]   [AFG]      [651]\n",
       "45            [Mohammad, Nabi]   [AFG]      [325]\n",
       "46              [Rashid, Khan]   [AFG]      [290]\n",
       "47         [Mitchell, Santner]    [NZ]      [275]\n",
       "48            [Sikandar, Raza]   [ZIM]      [261]\n",
       "49          [Zeeshan, Maqsood]   [OMA]      [238]\n",
       "50             [Mehedi, Hasan]   [BAN]      [238]\n",
       "51             [Chris, Woakes]   [ENG]      [235]\n",
       "52            [Glenn, Maxwell]   [AUS]      [227]\n",
       "53               [Imad, Wasim]   [PAK]      [220]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b86a7",
   "metadata": {},
   "source": [
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3ae5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "icc_bowler = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6d5c67ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81f7e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup5 = BeautifulSoup(icc_bowler.content)\n",
    "#print(soup5.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41ce343f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Josh', 'Hazlewood'],\n",
       " ['Mujeeb', 'Ur', 'Rahman'],\n",
       " ['Jasprit', 'Bumrah'],\n",
       " ['Shaheen', 'Afridi'],\n",
       " ['Mohammad', 'Nabi'],\n",
       " ['Mehedi', 'Hasan'],\n",
       " ['Matt', 'Henry'],\n",
       " ['Mitchell', 'Starc'],\n",
       " ['Rashid', 'Khan'],\n",
       " ['Mustafizur', 'Rahman'],\n",
       " ['Chris', 'Woakes'],\n",
       " ['Andy', 'McBrine'],\n",
       " ['Kagiso', 'Rabada'],\n",
       " ['Adam', 'Zampa'],\n",
       " ['Shakib', 'Al', 'Hasan'],\n",
       " ['Alzarri', 'Joseph'],\n",
       " ['Yuzvendra', 'Chahal'],\n",
       " ['Pat', 'Cummins'],\n",
       " ['Mitchell', 'Santner'],\n",
       " ['Lungi', 'Ngidi'],\n",
       " ['Mark', 'Watt'],\n",
       " ['Akeal', 'Hosein'],\n",
       " ['David', 'Willey'],\n",
       " ['Tabraiz', 'Shamsi'],\n",
       " ['Ahmed', 'Raza'],\n",
       " ['Akila', 'Dananjaya'],\n",
       " ['Mark', 'Wood'],\n",
       " ['Keshav', 'Maharaj'],\n",
       " ['Dushmantha', 'Chameera'],\n",
       " ['Shadab', 'Khan'],\n",
       " ['Bhuvneshwar', 'Kumar'],\n",
       " ['Kuldeep', 'Yadav'],\n",
       " ['Sandeep', 'Lamichhane'],\n",
       " ['Bilal', 'Khan'],\n",
       " ['Mohammad', 'Shami'],\n",
       " ['Wanindu', 'Hasaranga'],\n",
       " ['Tim', 'Southee'],\n",
       " ['Lachlan', 'Ferguson'],\n",
       " ['Adil', 'Rashid'],\n",
       " ['Saurabh', 'Netravalkar'],\n",
       " ['Taskin', 'Ahmed'],\n",
       " ['Mohammad', 'Nawaz'],\n",
       " ['Simi', 'Singh'],\n",
       " ['Ravindra', 'Jadeja'],\n",
       " ['Dwaine', 'Pretorius'],\n",
       " ['Haris', 'Rauf'],\n",
       " ['Zeeshan', 'Maqsood'],\n",
       " ['M.', 'Prasidh', 'Krishna'],\n",
       " ['Chad', 'Soper'],\n",
       " ['Colin', 'de', 'Grandhomme'],\n",
       " ['Hamza', 'Tahir'],\n",
       " ['Rohan', 'Mustafa'],\n",
       " ['Blessing', 'Muzarabani'],\n",
       " ['Taijul', 'Islam'],\n",
       " ['Jason', 'Holder'],\n",
       " ['Kaleemullah'],\n",
       " ['Craig', 'Young'],\n",
       " ['Ish', 'Sodhi'],\n",
       " ['Andile', 'Phehlukwayo'],\n",
       " ['Shardul', 'Thakur'],\n",
       " ['Joshua', 'Little'],\n",
       " ['Imad', 'Wasim'],\n",
       " ['Sheldon', 'Cottrell'],\n",
       " ['Anrich', 'Nortje'],\n",
       " ['Hasan', 'Ali'],\n",
       " ['Reece', 'Topley'],\n",
       " ['Dhananjaya', 'de', 'Silva'],\n",
       " ['Jhye', 'Richardson'],\n",
       " ['Safyaan', 'Sharif'],\n",
       " ['Mohammed', 'Siraj'],\n",
       " ['Moeen', 'Ali'],\n",
       " ['Sikandar', 'Raza'],\n",
       " ['Ashton', 'Agar'],\n",
       " ['Maheesh', 'Theekshana'],\n",
       " ['Fred', 'Klaassen'],\n",
       " ['Michael', 'Leask'],\n",
       " ['Nuwan', 'Pradeep'],\n",
       " ['Mohammad', 'Mohammad', 'Saifuddin'],\n",
       " ['Jan', 'Frylinck'],\n",
       " ['Jeffrey', 'Vandersay'],\n",
       " ['Nosthush', 'Kenjige'],\n",
       " ['Tendai', 'Chatara'],\n",
       " ['Akshar', 'Patel'],\n",
       " ['Saqib', 'Mahmood'],\n",
       " ['Wahab', 'Riaz'],\n",
       " ['Hardik', 'Pandya'],\n",
       " ['Faheem', 'Ashraf'],\n",
       " ['Richard', 'Ngarava'],\n",
       " ['Assad', 'Vala'],\n",
       " ['Zahoor', 'Khan'],\n",
       " ['Tom', 'Curran'],\n",
       " ['Khawar', 'Ali'],\n",
       " ['Sean', 'Abbott'],\n",
       " ['Jimmy', 'Neesham'],\n",
       " ['Logan', 'van', 'Beek'],\n",
       " ['Mark', 'Adair'],\n",
       " ['Sompal', 'Kami'],\n",
       " ['Karan', 'KC'],\n",
       " ['Norman', 'Vanua']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci bowler names\n",
    "\n",
    "bowler_names = []\n",
    "\n",
    "for i in soup5.find_all('td', class_=\"table-body__cell rankings-table__name name\"):\n",
    "    bowler_names.append(i.text.split())\n",
    "    \n",
    "bowler_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e30899fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AUS'],\n",
       " ['AFG'],\n",
       " ['IND'],\n",
       " ['PAK'],\n",
       " ['AFG'],\n",
       " ['BAN'],\n",
       " ['NZ'],\n",
       " ['AUS'],\n",
       " ['AFG'],\n",
       " ['BAN'],\n",
       " ['ENG'],\n",
       " ['IRE'],\n",
       " ['SA'],\n",
       " ['AUS'],\n",
       " ['BAN'],\n",
       " ['WI'],\n",
       " ['IND'],\n",
       " ['AUS'],\n",
       " ['NZ'],\n",
       " ['SA'],\n",
       " ['SCO'],\n",
       " ['WI'],\n",
       " ['ENG'],\n",
       " ['SA'],\n",
       " ['UAE'],\n",
       " ['SL'],\n",
       " ['ENG'],\n",
       " ['SA'],\n",
       " ['SL'],\n",
       " ['PAK'],\n",
       " ['IND'],\n",
       " ['IND'],\n",
       " ['NEP'],\n",
       " ['OMA'],\n",
       " ['IND'],\n",
       " ['SL'],\n",
       " ['NZ'],\n",
       " ['NZ'],\n",
       " ['ENG'],\n",
       " ['USA'],\n",
       " ['BAN'],\n",
       " ['PAK'],\n",
       " ['IRE'],\n",
       " ['IND'],\n",
       " ['SA'],\n",
       " ['PAK'],\n",
       " ['OMA'],\n",
       " ['IND'],\n",
       " ['PNG'],\n",
       " ['NZ'],\n",
       " ['SCO'],\n",
       " ['UAE'],\n",
       " ['ZIM'],\n",
       " ['BAN'],\n",
       " ['WI'],\n",
       " ['OMA'],\n",
       " ['IRE'],\n",
       " ['NZ'],\n",
       " ['SA'],\n",
       " ['IND'],\n",
       " ['IRE'],\n",
       " ['PAK'],\n",
       " ['WI'],\n",
       " ['SA'],\n",
       " ['PAK'],\n",
       " ['ENG'],\n",
       " ['SL'],\n",
       " ['AUS'],\n",
       " ['SCO'],\n",
       " ['IND'],\n",
       " ['ENG'],\n",
       " ['ZIM'],\n",
       " ['AUS'],\n",
       " ['SL'],\n",
       " ['NED'],\n",
       " ['SCO'],\n",
       " ['SL'],\n",
       " ['BAN'],\n",
       " ['NAM'],\n",
       " ['SL'],\n",
       " ['USA'],\n",
       " ['ZIM'],\n",
       " ['IND'],\n",
       " ['ENG'],\n",
       " ['PAK'],\n",
       " ['IND'],\n",
       " ['PAK'],\n",
       " ['ZIM'],\n",
       " ['PNG'],\n",
       " ['UAE'],\n",
       " ['ENG'],\n",
       " ['OMA'],\n",
       " ['AUS'],\n",
       " ['NZ'],\n",
       " ['NED'],\n",
       " ['IRE'],\n",
       " ['NEP'],\n",
       " ['NEP'],\n",
       " ['PNG']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci bowlers country names\n",
    "\n",
    "bowler_country = []\n",
    "\n",
    "for i in soup5.find_all('td', class_=\"table-body__cell nationality-logo rankings-table__team\"):\n",
    "    bowler_country.append(i.text.split())\n",
    "    \n",
    "bowler_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00806b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['718'],\n",
       " ['676'],\n",
       " ['662'],\n",
       " ['661'],\n",
       " ['657'],\n",
       " ['655'],\n",
       " ['654'],\n",
       " ['653'],\n",
       " ['651'],\n",
       " ['640'],\n",
       " ['640'],\n",
       " ['630'],\n",
       " ['625'],\n",
       " ['622'],\n",
       " ['619'],\n",
       " ['609'],\n",
       " ['604'],\n",
       " ['600'],\n",
       " ['596'],\n",
       " ['577'],\n",
       " ['574'],\n",
       " ['573'],\n",
       " ['569'],\n",
       " ['567'],\n",
       " ['555'],\n",
       " ['546'],\n",
       " ['543'],\n",
       " ['541'],\n",
       " ['537'],\n",
       " ['536'],\n",
       " ['535'],\n",
       " ['535'],\n",
       " ['534'],\n",
       " ['532'],\n",
       " ['532'],\n",
       " ['531'],\n",
       " ['524'],\n",
       " ['521'],\n",
       " ['506'],\n",
       " ['501'],\n",
       " ['498'],\n",
       " ['495'],\n",
       " ['493'],\n",
       " ['491'],\n",
       " ['485'],\n",
       " ['479'],\n",
       " ['478'],\n",
       " ['473'],\n",
       " ['473'],\n",
       " ['473'],\n",
       " ['472'],\n",
       " ['470'],\n",
       " ['470'],\n",
       " ['469'],\n",
       " ['464'],\n",
       " ['462'],\n",
       " ['462'],\n",
       " ['461'],\n",
       " ['459'],\n",
       " ['455'],\n",
       " ['454'],\n",
       " ['452'],\n",
       " ['452'],\n",
       " ['450'],\n",
       " ['449'],\n",
       " ['449'],\n",
       " ['449'],\n",
       " ['448'],\n",
       " ['448'],\n",
       " ['447'],\n",
       " ['445'],\n",
       " ['434'],\n",
       " ['434'],\n",
       " ['433'],\n",
       " ['433'],\n",
       " ['432'],\n",
       " ['432'],\n",
       " ['428'],\n",
       " ['423'],\n",
       " ['422'],\n",
       " ['420'],\n",
       " ['417'],\n",
       " ['416'],\n",
       " ['415'],\n",
       " ['415'],\n",
       " ['414'],\n",
       " ['413'],\n",
       " ['413'],\n",
       " ['411'],\n",
       " ['408'],\n",
       " ['399'],\n",
       " ['398'],\n",
       " ['398'],\n",
       " ['397'],\n",
       " ['394'],\n",
       " ['390'],\n",
       " ['390'],\n",
       " ['387'],\n",
       " ['383']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci Bowler rating\n",
    "\n",
    "bowler_rating = []\n",
    "\n",
    "for i in soup5.find_all('td', class_=\"table-body__cell rating\"):\n",
    "    bowler_rating.append(i.text.split())\n",
    "    \n",
    "bowler_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7496e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataframe of bowler to create table\n",
    "\n",
    "df_ball = pd.DataFrame({'BOWLER':bowler_names, 'COUNTRY':bowler_country, 'ICC_RATING':bowler_rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8db5a331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOWLER</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>ICC_RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Josh, Hazlewood]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Mujeeb, Ur, Rahman]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Jasprit, Bumrah]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[662]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Shaheen, Afridi]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[661]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Mohammad, Nabi]</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[657]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[Logan, van, Beek]</td>\n",
       "      <td>[NED]</td>\n",
       "      <td>[394]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[Mark, Adair]</td>\n",
       "      <td>[IRE]</td>\n",
       "      <td>[390]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Sompal, Kami]</td>\n",
       "      <td>[NEP]</td>\n",
       "      <td>[390]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[Karan, KC]</td>\n",
       "      <td>[NEP]</td>\n",
       "      <td>[387]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[Norman, Vanua]</td>\n",
       "      <td>[PNG]</td>\n",
       "      <td>[383]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  BOWLER COUNTRY ICC_RATING\n",
       "0      [Josh, Hazlewood]   [AUS]      [718]\n",
       "1   [Mujeeb, Ur, Rahman]   [AFG]      [676]\n",
       "2      [Jasprit, Bumrah]   [IND]      [662]\n",
       "3      [Shaheen, Afridi]   [PAK]      [661]\n",
       "4       [Mohammad, Nabi]   [AFG]      [657]\n",
       "..                   ...     ...        ...\n",
       "94    [Logan, van, Beek]   [NED]      [394]\n",
       "95         [Mark, Adair]   [IRE]      [390]\n",
       "96        [Sompal, Kami]   [NEP]      [390]\n",
       "97           [Karan, KC]   [NEP]      [387]\n",
       "98       [Norman, Vanua]   [PNG]      [383]\n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33894c85",
   "metadata": {},
   "source": [
    "# 6)\tWrite a python program to scrape cricket rankings from icc-cricket.com. You have to scrape: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a0ecb9",
   "metadata": {},
   "source": [
    "a)\tTop 10 ODI teams in women’s cricket along with the records for matches, points and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a7f93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "icc_womens_team = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f3743bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_womens_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3b4ded6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup6 = BeautifulSoup(icc_womens_team.content)\n",
    "#print(soup6.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a2bc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['England', 'ENG'],\n",
       " ['South', 'Africa', 'SA'],\n",
       " ['India', 'IND'],\n",
       " ['New', 'Zealand', 'NZ'],\n",
       " ['West', 'Indies', 'WI'],\n",
       " ['Bangladesh', 'BAN'],\n",
       " ['Pakistan', 'PAK'],\n",
       " ['Ireland', 'IRE'],\n",
       " ['Sri', 'Lanka', 'SL'],\n",
       " ['Zimbabwe', 'ZIM']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icc womens team name\n",
    "\n",
    "womens_team = []\n",
    "\n",
    "for i in soup6.find_all('td', class_=\"table-body__cell rankings-table__team\"):\n",
    "    womens_team.append(i.text.split())\n",
    "    \n",
    "womens_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46fd8c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['34'],\n",
       " ['4,097'],\n",
       " ['35'],\n",
       " ['4,157'],\n",
       " ['33'],\n",
       " ['3,392'],\n",
       " ['32'],\n",
       " ['3,161'],\n",
       " ['31'],\n",
       " ['2,815'],\n",
       " ['12'],\n",
       " ['930'],\n",
       " ['30'],\n",
       " ['1,962'],\n",
       " ['11'],\n",
       " ['516'],\n",
       " ['11'],\n",
       " ['495'],\n",
       " ['8'],\n",
       " ['0']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci womens team points and matches\n",
    "\n",
    "womens_match = []\n",
    "\n",
    "for i in soup6.find_all('td', class_=\"table-body__cell u-center-text\"):\n",
    "    womens_match.append(i.text.split())\n",
    "    \n",
    "womens_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d8801d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['121', '119', '103', '99', '91', '78', '65', '47', '45', '0']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci womens team rating\n",
    "\n",
    "womens_team_rating = []\n",
    "\n",
    "for i in soup6.find_all('td', class_=\"table-body__cell u-text-right rating\"):\n",
    "    womens_team_rating.append(i.text)\n",
    "    \n",
    "womens_team_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba2468",
   "metadata": {},
   "source": [
    "b)\tTop 10 women’s ODI Batting players along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00579355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "wm_batsman = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d235c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_batsman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe6a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup7 = BeautifulSoup(wm_batsman.content)\n",
    "#print(soup7.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37b40b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Beth', 'Mooney'],\n",
       " ['Natalie', 'Sciver'],\n",
       " ['Laura', 'Wolvaardt'],\n",
       " ['Meg', 'Lanning'],\n",
       " ['Rachael', 'Haynes'],\n",
       " ['Smriti', 'Mandhana'],\n",
       " ['Amy', 'Satterthwaite'],\n",
       " ['Harmanpreet', 'Kaur'],\n",
       " ['Chamari', 'Athapaththu'],\n",
       " ['Tammy', 'Beaumont'],\n",
       " ['Ellyse', 'Perry'],\n",
       " ['Deandra', 'Dottin'],\n",
       " ['Stafanie', 'Taylor'],\n",
       " ['Amelia', 'Kerr'],\n",
       " ['Sophie', 'Devine'],\n",
       " ['Heather', 'Knight'],\n",
       " ['Marizanne', 'Kapp'],\n",
       " ['Suzie', 'Bates'],\n",
       " ['Chloe-Lesleigh', 'Tryon'],\n",
       " ['Hayley', 'Matthews'],\n",
       " ['Mignon', 'du', 'Preez'],\n",
       " ['Danielle', 'Wyatt'],\n",
       " ['Ashleigh', 'Gardner'],\n",
       " ['Bismah', 'Maroof'],\n",
       " ['Sune', 'Luus'],\n",
       " ['Gaby', 'Lewis'],\n",
       " ['Fargana', 'Hoque'],\n",
       " ['Sophia', 'Dunkley'],\n",
       " ['Aliya', 'Riaz'],\n",
       " ['Maddie', 'Green'],\n",
       " ['Deepti', 'Sharma'],\n",
       " ['Laura', 'Delany'],\n",
       " ['Amy', 'Jones'],\n",
       " ['Tahlia', 'McGrath'],\n",
       " ['Sidra', 'Ameen'],\n",
       " ['Yastika', 'Bhatia'],\n",
       " ['Shafali', 'Verma'],\n",
       " ['Nahida', 'Khan'],\n",
       " ['Katey', 'Martin'],\n",
       " ['Rumana', 'Ahmed'],\n",
       " ['Nida', 'Dar'],\n",
       " ['Poonam', 'Raut'],\n",
       " ['Harshitha', 'Madavi'],\n",
       " ['Umaima', 'Sohail'],\n",
       " ['Lara', 'Goodall'],\n",
       " ['Nilakshi', 'Silva'],\n",
       " ['Javeria', 'Khan'],\n",
       " ['Leah', 'Paul'],\n",
       " ['Shemaine', 'Campbelle'],\n",
       " ['Dane', 'van', 'Niekerk'],\n",
       " ['Katherine', 'Brunt'],\n",
       " ['Pooja', 'Vastrakar'],\n",
       " ['Brooke', 'Halliday'],\n",
       " ['Muneeba', 'Ali'],\n",
       " ['Amy', 'Hunter'],\n",
       " ['Jess', 'Jonassen'],\n",
       " ['Nigar', 'Sultana'],\n",
       " ['Sharmin', 'Supta'],\n",
       " ['Salma', 'Khatun'],\n",
       " ['Lauren', 'Winfield'],\n",
       " ['Jhulan', 'Goswami'],\n",
       " ['Chedean', 'Nation'],\n",
       " ['Emma', 'Lamb'],\n",
       " ['Trisha', 'Chetty'],\n",
       " ['Andrie', 'Steyn'],\n",
       " ['Richa', 'Ghosh'],\n",
       " ['Lata', 'Mondal'],\n",
       " ['Prasadani', 'Weerakkody'],\n",
       " ['Lauren', 'Down'],\n",
       " ['Katie', 'Perkins'],\n",
       " ['Sophie', 'Ecclestone'],\n",
       " ['Orla', 'Prendergast'],\n",
       " ['Nicola', 'Carey'],\n",
       " ['Hasini', 'Perera'],\n",
       " ['Kavisha', 'Dilhari'],\n",
       " ['Kycia', 'Knight'],\n",
       " ['Mary', 'Waldron'],\n",
       " ['Murshida', 'Khatun'],\n",
       " ['Shamima', 'Sultana'],\n",
       " ['Annabel', 'Sutherland'],\n",
       " ['Mary-Anne', 'Musonda'],\n",
       " ['Georgina', 'Dempsey'],\n",
       " ['Jess', 'Kerr'],\n",
       " ['Kate', 'Cross'],\n",
       " ['Charlotte', 'Dean'],\n",
       " ['Shikha', 'Pandey'],\n",
       " ['Ritu', 'Moni'],\n",
       " ['Tazmin', 'Brits'],\n",
       " ['Kyshona', 'Knight'],\n",
       " ['Josephine', 'Nkomo'],\n",
       " ['Rajeshwari', 'Gayakwad'],\n",
       " ['Jemimah', 'Rodriques'],\n",
       " ['Sophie', 'MacMahon'],\n",
       " ['Lea', 'Tahuhu'],\n",
       " ['Meghna', 'Singh'],\n",
       " ['Hayley', 'Jensen'],\n",
       " ['Sneh', 'Rana'],\n",
       " ['Frederique', 'Overdijk'],\n",
       " ['Anushka', 'Sanjeewani']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci women batsmen names\n",
    "\n",
    "wm_batsmen = []\n",
    "\n",
    "for i in soup7.find_all('td', class_=\"table-body__cell rankings-table__name name\"):\n",
    "    wm_batsmen.append(i.text.split())\n",
    "    \n",
    "wm_batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8feaf746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AUS'],\n",
       " ['ENG'],\n",
       " ['SA'],\n",
       " ['AUS'],\n",
       " ['AUS'],\n",
       " ['IND'],\n",
       " ['NZ'],\n",
       " ['IND'],\n",
       " ['SL'],\n",
       " ['ENG'],\n",
       " ['AUS'],\n",
       " ['WI'],\n",
       " ['WI'],\n",
       " ['NZ'],\n",
       " ['NZ'],\n",
       " ['ENG'],\n",
       " ['SA'],\n",
       " ['NZ'],\n",
       " ['SA'],\n",
       " ['WI'],\n",
       " ['SA'],\n",
       " ['ENG'],\n",
       " ['AUS'],\n",
       " ['PAK'],\n",
       " ['SA'],\n",
       " ['IRE'],\n",
       " ['BAN'],\n",
       " ['ENG'],\n",
       " ['PAK'],\n",
       " ['NZ'],\n",
       " ['IND'],\n",
       " ['IRE'],\n",
       " ['ENG'],\n",
       " ['AUS'],\n",
       " ['PAK'],\n",
       " ['IND'],\n",
       " ['IND'],\n",
       " ['PAK'],\n",
       " ['NZ'],\n",
       " ['BAN'],\n",
       " ['PAK'],\n",
       " ['IND'],\n",
       " ['SL'],\n",
       " ['PAK'],\n",
       " ['SA'],\n",
       " ['SL'],\n",
       " ['PAK'],\n",
       " ['IRE'],\n",
       " ['WI'],\n",
       " ['SA'],\n",
       " ['ENG'],\n",
       " ['IND'],\n",
       " ['NZ'],\n",
       " ['PAK'],\n",
       " ['IRE'],\n",
       " ['AUS'],\n",
       " ['BAN'],\n",
       " ['BAN'],\n",
       " ['BAN'],\n",
       " ['ENG'],\n",
       " ['IND'],\n",
       " ['WI'],\n",
       " ['ENG'],\n",
       " ['SA'],\n",
       " ['SA'],\n",
       " ['IND'],\n",
       " ['BAN'],\n",
       " ['SL'],\n",
       " ['NZ'],\n",
       " ['NZ'],\n",
       " ['ENG'],\n",
       " ['IRE'],\n",
       " ['AUS'],\n",
       " ['SL'],\n",
       " ['SL'],\n",
       " ['WI'],\n",
       " ['IRE'],\n",
       " ['BAN'],\n",
       " ['BAN'],\n",
       " ['AUS'],\n",
       " ['ZIM'],\n",
       " ['IRE'],\n",
       " ['NZ'],\n",
       " ['ENG'],\n",
       " ['ENG'],\n",
       " ['IND'],\n",
       " ['BAN'],\n",
       " ['SA'],\n",
       " ['WI'],\n",
       " ['ZIM'],\n",
       " ['IND'],\n",
       " ['IND'],\n",
       " ['IRE'],\n",
       " ['NZ'],\n",
       " ['IND'],\n",
       " ['NZ'],\n",
       " ['IND'],\n",
       " ['NED'],\n",
       " ['SL']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci women team names\n",
    "\n",
    "wm_team = []\n",
    "\n",
    "for i in soup7.find_all('span', class_=\"table-body__logo-text\"):\n",
    "    wm_team.append(i.text.split())\n",
    "    \n",
    "wm_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "457ccbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['749'],\n",
       " ['740'],\n",
       " ['732'],\n",
       " ['710'],\n",
       " ['701'],\n",
       " ['698'],\n",
       " ['681'],\n",
       " ['662'],\n",
       " ['655'],\n",
       " ['645'],\n",
       " ['642'],\n",
       " ['626'],\n",
       " ['618'],\n",
       " ['598'],\n",
       " ['591'],\n",
       " ['585'],\n",
       " ['585'],\n",
       " ['569'],\n",
       " ['557'],\n",
       " ['555'],\n",
       " ['548'],\n",
       " ['535'],\n",
       " ['507'],\n",
       " ['506'],\n",
       " ['496'],\n",
       " ['494'],\n",
       " ['493'],\n",
       " ['482'],\n",
       " ['474'],\n",
       " ['474'],\n",
       " ['462'],\n",
       " ['455'],\n",
       " ['447'],\n",
       " ['445'],\n",
       " ['445'],\n",
       " ['438'],\n",
       " ['432'],\n",
       " ['423'],\n",
       " ['420'],\n",
       " ['419'],\n",
       " ['411'],\n",
       " ['405'],\n",
       " ['402'],\n",
       " ['396'],\n",
       " ['394'],\n",
       " ['384'],\n",
       " ['382'],\n",
       " ['377'],\n",
       " ['377'],\n",
       " ['363'],\n",
       " ['363'],\n",
       " ['361'],\n",
       " ['346'],\n",
       " ['346'],\n",
       " ['343'],\n",
       " ['340'],\n",
       " ['339'],\n",
       " ['331'],\n",
       " ['323'],\n",
       " ['321'],\n",
       " ['319'],\n",
       " ['316'],\n",
       " ['314'],\n",
       " ['314'],\n",
       " ['311'],\n",
       " ['308'],\n",
       " ['301'],\n",
       " ['298'],\n",
       " ['294'],\n",
       " ['293'],\n",
       " ['291'],\n",
       " ['275'],\n",
       " ['274'],\n",
       " ['267'],\n",
       " ['266'],\n",
       " ['263'],\n",
       " ['255'],\n",
       " ['252'],\n",
       " ['248'],\n",
       " ['246'],\n",
       " ['244'],\n",
       " ['239'],\n",
       " ['238'],\n",
       " ['237'],\n",
       " ['236'],\n",
       " ['233'],\n",
       " ['230'],\n",
       " ['224'],\n",
       " ['224'],\n",
       " ['222'],\n",
       " ['221'],\n",
       " ['214'],\n",
       " ['213'],\n",
       " ['213'],\n",
       " ['212'],\n",
       " ['212'],\n",
       " ['211'],\n",
       " ['210'],\n",
       " ['209']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci womens batsman rating\n",
    "\n",
    "wmbts_rating = []\n",
    "\n",
    "for i in soup7.find_all('td', class_=\"table-body__cell rating\"):\n",
    "    wmbts_rating.append(i.text.split())\n",
    "    \n",
    "wmbts_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bc3d34",
   "metadata": {},
   "source": [
    "c)\tTop 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "36cb2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "wm_allrounder = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08fa8673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_allrounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d7abbf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup8 = BeautifulSoup(wm_allrounder.content)\n",
    "#print(soup8.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3c6abc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Natalie', 'Sciver'],\n",
       " ['Marizanne', 'Kapp'],\n",
       " ['Hayley', 'Matthews'],\n",
       " ['Amelia', 'Kerr'],\n",
       " ['Deepti', 'Sharma'],\n",
       " ['Ashleigh', 'Gardner'],\n",
       " ['Jess', 'Jonassen'],\n",
       " ['Jhulan', 'Goswami'],\n",
       " ['Sophie', 'Ecclestone'],\n",
       " ['Katherine', 'Brunt'],\n",
       " ['Stafanie', 'Taylor'],\n",
       " ['Sophie', 'Devine'],\n",
       " ['Rumana', 'Ahmed'],\n",
       " ['Nida', 'Dar'],\n",
       " ['Chloe-Lesleigh', 'Tryon'],\n",
       " ['Salma', 'Khatun'],\n",
       " ['Chamari', 'Athapaththu'],\n",
       " ['Sune', 'Luus'],\n",
       " ['Harmanpreet', 'Kaur']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci womens odi all rounder players name\n",
    "\n",
    "allro_players = []\n",
    "\n",
    "for i in soup8.find_all('td', class_=\"table-body__cell rankings-table__name name\"):\n",
    "    allro_players.append(i.text.split())\n",
    "    \n",
    "allro_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34924f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ENG'],\n",
       " ['SA'],\n",
       " ['WI'],\n",
       " ['NZ'],\n",
       " ['IND'],\n",
       " ['AUS'],\n",
       " ['AUS'],\n",
       " ['IND'],\n",
       " ['ENG'],\n",
       " ['ENG'],\n",
       " ['WI'],\n",
       " ['NZ'],\n",
       " ['BAN'],\n",
       " ['PAK'],\n",
       " ['SA'],\n",
       " ['BAN'],\n",
       " ['SL'],\n",
       " ['SA'],\n",
       " ['IND']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci womens odi all rounder players country\n",
    "\n",
    "allro_players_con = []\n",
    "\n",
    "for i in soup8.find_all('span', class_=\"table-body__logo-text\"):\n",
    "    allro_players_con.append(i.text.split())\n",
    "    \n",
    "allro_players_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28f843fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['372'],\n",
       " ['349'],\n",
       " ['339'],\n",
       " ['336'],\n",
       " ['271'],\n",
       " ['270'],\n",
       " ['246'],\n",
       " ['219'],\n",
       " ['217'],\n",
       " ['215'],\n",
       " ['207'],\n",
       " ['202'],\n",
       " ['201'],\n",
       " ['200'],\n",
       " ['197'],\n",
       " ['178'],\n",
       " ['178'],\n",
       " ['171'],\n",
       " ['160']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci womens allrounder players rating\n",
    "\n",
    "wm_allrou_rating = []\n",
    "\n",
    "for i in soup8.find_all('td', class_=\"table-body__cell rating\"):\n",
    "    wm_allrou_rating.append(i.text.split())\n",
    "    \n",
    "wm_allrou_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "594f8b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['395', 'v', 'South', 'Africa,', '11/07/2022'],\n",
       " ['419', 'v', 'West', 'Indies,', '10/09/2021'],\n",
       " ['365', 'v', 'India,', '12/03/2022'],\n",
       " ['339', 'v', 'South', 'Africa,', '17/03/2022'],\n",
       " ['397', 'v', 'South', 'Africa,', '09/10/2019'],\n",
       " ['279', 'v', 'West', 'Indies,', '30/03/2022'],\n",
       " ['308', 'v', 'West', 'Indies,', '11/09/2019'],\n",
       " ['308', 'v', 'Australia,', '02/02/2016'],\n",
       " ['217', 'v', 'South', 'Africa,', '31/03/2022'],\n",
       " ['296', 'v', 'Australia,', '03/02/2022'],\n",
       " ['559', 'v', 'New', 'Zealand,', '10/10/2013'],\n",
       " ['305', 'v', 'Australia,', '05/10/2020'],\n",
       " ['198', 'v', 'South', 'Africa,', '05/03/2022'],\n",
       " ['206', 'v', 'Sri', 'Lanka,', '03/06/2022'],\n",
       " ['197', 'v', 'England,', '18/07/2022'],\n",
       " ['170', 'v', 'Australia,', '25/03/2022'],\n",
       " ['187', 'v', 'South', 'Africa,', '17/02/2019'],\n",
       " ['223', 'v', 'Ireland,', '17/06/2022'],\n",
       " ['174', 'v', 'South', 'Africa,', '14/03/2021']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap icci womens allrounder players career best rating\n",
    "\n",
    "wm_career_rating = []\n",
    "\n",
    "for i in soup8.find_all('td', class_=\"table-body__cell u-text-right u-hide-phablet\"):\n",
    "    wm_career_rating.append(i.text.split())\n",
    "    \n",
    "wm_career_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07144563",
   "metadata": {},
   "source": [
    "# Make Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d5b2342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19 19 19\n"
     ]
    }
   ],
   "source": [
    "print(len(allro_players), len(allro_players_con), len(wm_allrou_rating), len(wm_career_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5ae5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e73dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frame table of womens all rounder players\n",
    "\n",
    "df_wm_allrou_players = pd.DataFrame({'WOMENS_PLAYER_NAME':allro_players, 'COUNTRY_NAMES':allro_players_con, 'WM_ICC_RATING':wm_allrou_rating, 'CAREER_RATING':wm_career_rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f29e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WOMENS_PLAYER_NAME</th>\n",
       "      <th>COUNTRY_NAMES</th>\n",
       "      <th>WM_ICC_RATING</th>\n",
       "      <th>CAREER_RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Natalie, Sciver]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[372]</td>\n",
       "      <td>[395, v, South, Africa,, 11/07/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Marizanne, Kapp]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[349]</td>\n",
       "      <td>[419, v, West, Indies,, 10/09/2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Hayley, Matthews]</td>\n",
       "      <td>[WI]</td>\n",
       "      <td>[339]</td>\n",
       "      <td>[365, v, India,, 12/03/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Amelia, Kerr]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[336]</td>\n",
       "      <td>[339, v, South, Africa,, 17/03/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Deepti, Sharma]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[271]</td>\n",
       "      <td>[397, v, South, Africa,, 09/10/2019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Ashleigh, Gardner]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[270]</td>\n",
       "      <td>[279, v, West, Indies,, 30/03/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Jess, Jonassen]</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[246]</td>\n",
       "      <td>[308, v, West, Indies,, 11/09/2019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Jhulan, Goswami]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[219]</td>\n",
       "      <td>[308, v, Australia,, 02/02/2016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Sophie, Ecclestone]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[217]</td>\n",
       "      <td>[217, v, South, Africa,, 31/03/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Katherine, Brunt]</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[215]</td>\n",
       "      <td>[296, v, Australia,, 03/02/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Stafanie, Taylor]</td>\n",
       "      <td>[WI]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>[559, v, New, Zealand,, 10/10/2013]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Sophie, Devine]</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[202]</td>\n",
       "      <td>[305, v, Australia,, 05/10/2020]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Rumana, Ahmed]</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>[201]</td>\n",
       "      <td>[198, v, South, Africa,, 05/03/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Nida, Dar]</td>\n",
       "      <td>[PAK]</td>\n",
       "      <td>[200]</td>\n",
       "      <td>[206, v, Sri, Lanka,, 03/06/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[Chloe-Lesleigh, Tryon]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[197]</td>\n",
       "      <td>[197, v, England,, 18/07/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[Salma, Khatun]</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>[178]</td>\n",
       "      <td>[170, v, Australia,, 25/03/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[Chamari, Athapaththu]</td>\n",
       "      <td>[SL]</td>\n",
       "      <td>[178]</td>\n",
       "      <td>[187, v, South, Africa,, 17/02/2019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[Sune, Luus]</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[171]</td>\n",
       "      <td>[223, v, Ireland,, 17/06/2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[Harmanpreet, Kaur]</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[160]</td>\n",
       "      <td>[174, v, South, Africa,, 14/03/2021]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WOMENS_PLAYER_NAME COUNTRY_NAMES WM_ICC_RATING  \\\n",
       "0         [Natalie, Sciver]         [ENG]         [372]   \n",
       "1         [Marizanne, Kapp]          [SA]         [349]   \n",
       "2        [Hayley, Matthews]          [WI]         [339]   \n",
       "3            [Amelia, Kerr]          [NZ]         [336]   \n",
       "4          [Deepti, Sharma]         [IND]         [271]   \n",
       "5       [Ashleigh, Gardner]         [AUS]         [270]   \n",
       "6          [Jess, Jonassen]         [AUS]         [246]   \n",
       "7         [Jhulan, Goswami]         [IND]         [219]   \n",
       "8      [Sophie, Ecclestone]         [ENG]         [217]   \n",
       "9        [Katherine, Brunt]         [ENG]         [215]   \n",
       "10       [Stafanie, Taylor]          [WI]         [207]   \n",
       "11         [Sophie, Devine]          [NZ]         [202]   \n",
       "12          [Rumana, Ahmed]         [BAN]         [201]   \n",
       "13              [Nida, Dar]         [PAK]         [200]   \n",
       "14  [Chloe-Lesleigh, Tryon]          [SA]         [197]   \n",
       "15          [Salma, Khatun]         [BAN]         [178]   \n",
       "16   [Chamari, Athapaththu]          [SL]         [178]   \n",
       "17             [Sune, Luus]          [SA]         [171]   \n",
       "18      [Harmanpreet, Kaur]         [IND]         [160]   \n",
       "\n",
       "                           CAREER_RATING  \n",
       "0   [395, v, South, Africa,, 11/07/2022]  \n",
       "1    [419, v, West, Indies,, 10/09/2021]  \n",
       "2           [365, v, India,, 12/03/2022]  \n",
       "3   [339, v, South, Africa,, 17/03/2022]  \n",
       "4   [397, v, South, Africa,, 09/10/2019]  \n",
       "5    [279, v, West, Indies,, 30/03/2022]  \n",
       "6    [308, v, West, Indies,, 11/09/2019]  \n",
       "7       [308, v, Australia,, 02/02/2016]  \n",
       "8   [217, v, South, Africa,, 31/03/2022]  \n",
       "9       [296, v, Australia,, 03/02/2022]  \n",
       "10   [559, v, New, Zealand,, 10/10/2013]  \n",
       "11      [305, v, Australia,, 05/10/2020]  \n",
       "12  [198, v, South, Africa,, 05/03/2022]  \n",
       "13     [206, v, Sri, Lanka,, 03/06/2022]  \n",
       "14        [197, v, England,, 18/07/2022]  \n",
       "15      [170, v, Australia,, 25/03/2022]  \n",
       "16  [187, v, South, Africa,, 17/02/2019]  \n",
       "17        [223, v, Ireland,, 17/06/2022]  \n",
       "18  [174, v, South, Africa,, 14/03/2021]  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wm_allrou_players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40de7a9",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f7dfed6",
   "metadata": {},
   "source": [
    "i) Headline\n",
    "ii) Time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147fb6ec",
   "metadata": {},
   "source": [
    "i) Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ead6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "headlines = requests.get('https://www.cnbc.com/world/?region=world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08c540bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "763f9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup9 = BeautifulSoup(headlines.content)\n",
    "#print(soup9.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f67febc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pro', 'News', 'and', 'Analysis'],\n",
       " ['Sustainable', 'Future'],\n",
       " ['Coronavirus'],\n",
       " ['CNBC', 'Travel'],\n",
       " ['Make', 'It'],\n",
       " ['Investing', 'in', 'supertrends']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap news headings\n",
    "\n",
    "news_headline = []  #empty list\n",
    "\n",
    "for i in soup9.find_all('header', class_=\"SectionWrapper-header\"):\n",
    "    news_headline.append(i.text.split())\n",
    "    \n",
    "news_headline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e9ab68",
   "metadata": {},
   "source": [
    "ii) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd040033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap news times\n",
    "\n",
    "time = []  #empty list\n",
    "\n",
    "for i in soup9.find_all('time', class_=\"LatestNews-timestamp\"):\n",
    "    time.append(i.text)\n",
    "    \n",
    "time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e36155",
   "metadata": {},
   "source": [
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ef5c30f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#MainContent',\n",
       " '//www.cnbc.com/world/',\n",
       " '/',\n",
       " '/markets/',\n",
       " '/pre-markets/',\n",
       " '/us-markets/',\n",
       " '/markets-europe/',\n",
       " '/china-markets/',\n",
       " '/markets-asia-pacific/',\n",
       " '/world-markets/',\n",
       " '/currencies/',\n",
       " '/cryptocurrency/',\n",
       " '/futures-and-commodities/',\n",
       " '/bonds/',\n",
       " '/funds-and-etfs/',\n",
       " '/business/',\n",
       " '/economy/',\n",
       " '/finance/',\n",
       " '/health-and-science/',\n",
       " '/media/',\n",
       " '/real-estate/',\n",
       " '/energy/',\n",
       " '/climate/',\n",
       " '/transportation/',\n",
       " '/industrials/',\n",
       " '/retail/',\n",
       " '/wealth/',\n",
       " '/life/',\n",
       " '/small-business/',\n",
       " '/investing/',\n",
       " '/personal-finance/',\n",
       " '/fintech/',\n",
       " '/financial-advisors/',\n",
       " '/options-action/',\n",
       " '/etf-street/',\n",
       " 'https://buffett.cnbc.com',\n",
       " '/earnings/',\n",
       " '/trader-talk/',\n",
       " '/technology/',\n",
       " '/cybersecurity/',\n",
       " '/enterprise/',\n",
       " '/internet/',\n",
       " '/media/',\n",
       " '/mobile/',\n",
       " '/social-media/',\n",
       " '/cnbc-disruptors/',\n",
       " '/tech-guide/',\n",
       " '/politics/',\n",
       " '/white-house/',\n",
       " '/policy/',\n",
       " '/defense/',\n",
       " '/congress/',\n",
       " '/equity-opportunity/',\n",
       " '/europe-politics/',\n",
       " '/china-politics/',\n",
       " '/asia-politics/',\n",
       " '/world-politics/',\n",
       " '/tv/',\n",
       " '/live-audio/',\n",
       " '/latest-video/',\n",
       " '/top-video/',\n",
       " '/video-ceo-interviews/',\n",
       " '/europe-television/',\n",
       " '/asia-business-day/',\n",
       " '/podcast/',\n",
       " '/digital-original/',\n",
       " '/watchlist/',\n",
       " '/investingclub/',\n",
       " '/investingclub/cramer-trade-alert/',\n",
       " '/investingclub/cramers-morning-thoughts/',\n",
       " '/investingclub/analysis/',\n",
       " '/investingclub/morning-meeting/',\n",
       " '/investingclub/charitable-trust/',\n",
       " '/pro/',\n",
       " '/pro/news/',\n",
       " '/pro/',\n",
       " '#',\n",
       " '#',\n",
       " '/make-it/',\n",
       " '/?region=usa',\n",
       " '/world/',\n",
       " '/watchlist/',\n",
       " '#',\n",
       " '#',\n",
       " '/',\n",
       " '/markets/',\n",
       " '/business/',\n",
       " '/investing/',\n",
       " '/technology/',\n",
       " '/politics/',\n",
       " '/tv/',\n",
       " '/watchlist/',\n",
       " '/investingclub/',\n",
       " '/pro/',\n",
       " '#',\n",
       " '#',\n",
       " '#',\n",
       " '#',\n",
       " '#',\n",
       " 'https://www.cnbc.com/2022/09/23/european-stocks-expected-to-open-in-the-green-as-investors-digest-central-bank-moves-.html',\n",
       " 'https://www.cnbc.com/2022/09/23/stocks-could-continue-skittish-trading-until-interest-rate-move-calms-down.html',\n",
       " 'https://www.cnbc.com/quotes/US10Y',\n",
       " 'https://www.cnbc.com/2022/09/23/hedge-funds-ramp-up-market-bets-as-volatility-brings-the-asset-class-back-into-favor.html',\n",
       " 'https://www.cnbc.com/2022/09/23/citi-says-sterling-dollar-parity-is-possible-as-uk-risks-currency-crisis.html',\n",
       " 'https://www.cnbc.com/2022/09/24/convertible-sales-fall-in-us-amid-popularity-of-evs-suvs.html',\n",
       " 'https://www.cnbc.com/2022/09/22/charts-suggest-inflation-could-soon-come-down-substantially-jim-cramer-says.html',\n",
       " 'https://www.cnbc.com/2022/09/25/italy-poised-for-hard-right-leader-as-country-votes-in-snap-election.html',\n",
       " 'https://www.cnbc.com/2022/09/25/italy-poised-for-hard-right-leader-as-country-votes-in-snap-election.html',\n",
       " 'https://www.cnbc.com/video/2022/09/22/70-governments-in-77-years-why-italy-changes-governments-so-often.html',\n",
       " 'https://www.cnbc.com/2022/09/23/from-the-fed-to-europes-currency-crisis-heres-whats-behind-this-selloff-in-financial-markets.html',\n",
       " 'https://www.cnbc.com/2022/09/23/from-the-fed-to-europes-currency-crisis-heres-whats-behind-this-selloff-in-financial-markets.html',\n",
       " 'https://www.cnbc.com/2022/09/23/google-ceo-pichai-fields-questions-on-cost-cuts-at-all-hands-meeting-.html',\n",
       " 'https://www.cnbc.com/2022/09/23/google-ceo-pichai-fields-questions-on-cost-cuts-at-all-hands-meeting-.html',\n",
       " 'https://www.cnbc.com/2022/09/25/italy-poised-for-hard-right-leader-as-country-votes-in-snap-election.html',\n",
       " 'https://www.cnbc.com/2022/09/24/three-rules-for-a-successful-open-relationship.html',\n",
       " 'https://www.cnbc.com/2022/09/24/biden-administration-awards-1point5-billion-to-fight-opioid-crisis.html',\n",
       " 'https://www.cnbc.com/2022/09/24/top-10-cities-with-the-best-pizzerias-worldwide-.html',\n",
       " 'https://www.cnbc.com/2022/09/24/easy-meals-for-two-under-20-from-black-girls-in-trader-joes-creator.html',\n",
       " 'https://www.cnbc.com/2022/09/24/how-to-raise-resilient-kids-by-developing-their-brains-with-nurturing-routines-parenting-expert.html',\n",
       " 'https://www.cnbc.com/2022/09/24/how-airlines-plan-to-end-one-billion-tons-of-carbon-emissions.html',\n",
       " 'https://www.cnbc.com/2022/09/24/queer-eyes-karamo-brown-shares-morning-routine.html',\n",
       " 'https://www.cnbc.com/2022/09/24/vermont-new-mexico-california-us-states-with-least-air-pollution.html',\n",
       " 'https://www.cnbc.com/2022/09/24/new-york-now-no-1-port-in-us-as-sea-change-in-trade-hits-west-coast.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/09/24/analysts-name-top-high-conviction-stocks-for-playing-market-turbulence.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/09/24/feared-stock-market-bottom-retest-is-now-underway.html',\n",
       " 'https://www.cnbc.com/2022/09/24/wallethub-top-10-cities-to-retire-2022-nearly-half-are-in-florida.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/09/24/quantum-investing-perils-and-promise-of-quantum-computing-are-nearing.html',\n",
       " 'https://www.cnbc.com/2022/09/24/what-parent-plus-borrowers-need-to-know-about-student-loan-forgiveness.html',\n",
       " 'https://www.cnbc.com/2022/09/24/check-in-smoke-up-tune-out-cannabis-friendly-vacation-rentals-catch-on.html',\n",
       " 'https://www.cnbc.com/2022/09/24/convertible-sales-fall-in-us-amid-popularity-of-evs-suvs.html',\n",
       " 'https://www.cnbc.com/2022/09/24/liz-truss-britains-lurch-to-reaganomics-gets-thumbs-down-from-markets.html',\n",
       " '/investingclub/',\n",
       " 'https://www.cnbc.com/2022/09/23/it-was-another-painful-week-to-own-stocks-but-we-have-a-new-plan-for-monday.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/09/23/stocks-could-continue-skittish-trading-until-interest-rate-move-calms-down.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/09/23/pro-picks-watch-all-of-fridays-big-stock-calls-on-cnbc.html',\n",
       " 'https://www.cnbc.com/2022/09/23/careers-where-over-50percent-of-workers-are-happy-with-their-pay.html',\n",
       " 'https://www.cnbc.com/2022/09/23/new-york-ag-wrongly-says-yankees-game-on-apple-tv-costs-extra.html',\n",
       " 'https://www.cnbc.com/2022/09/23/tech-stocks-worst-two-week-stretch-since-the-start-of-pandemic.html',\n",
       " '/investingclub/',\n",
       " 'https://www.cnbc.com/2022/09/23/jim-cramer-sat-down-with-the-ceos-of-salesforce-and-slack-this-week.html',\n",
       " 'https://www.cnbc.com/2022/09/23/some-homebuyers-are-facing-payment-shock-ways-to-save-on-a-mortgage.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/09/23/ether-is-down-almost-20percent-since-the-merge-heres-whats-going-on.html',\n",
       " 'https://www.cnbc.com/2022/09/23/elon-musk-direct-reports-at-tesla.html',\n",
       " 'https://www.cnbc.com/2022/09/23/trump-merger-partner-shares-fall-dramatically.html',\n",
       " '/investingclub/',\n",
       " 'https://www.cnbc.com/2022/09/23/us-fiscal-policy-is-undermining-the-feds-efforts-to-fight-inflation.html',\n",
       " '/us-market-movers/',\n",
       " 'https://www.cnbc.com/2022/09/25/north-korea-fires-ballistic-missile-ahead-of-kamala-harris-visit.html',\n",
       " 'https://www.cnbc.com/2022/09/25/north-korea-fires-ballistic-missile-ahead-of-kamala-harris-visit.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/09/23/ether-is-down-almost-20percent-since-the-merge-heres-whats-going-on.html',\n",
       " 'https://www.cnbc.com/tanaya-macheel/',\n",
       " 'https://www.cnbc.com/2022/09/23/ether-is-down-almost-20percent-since-the-merge-heres-whats-going-on.html',\n",
       " 'https://www.cnbc.com/tanaya-macheel/',\n",
       " 'https://www.cnbc.com/2022/09/24/us-sending-dangerous-signals-on-taiwan-china-tells-blinken.html',\n",
       " 'https://www.cnbc.com/2022/09/24/us-sending-dangerous-signals-on-taiwan-china-tells-blinken.html',\n",
       " 'https://www.cnbc.com/2022/09/24/new-york-now-no-1-port-in-us-as-sea-change-in-trade-hits-west-coast.html',\n",
       " 'https://www.cnbc.com/lori-ann-larocco/',\n",
       " 'https://www.cnbc.com/2022/09/24/new-york-now-no-1-port-in-us-as-sea-change-in-trade-hits-west-coast.html',\n",
       " 'https://www.cnbc.com/lori-ann-larocco/',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/09/24/feared-stock-market-bottom-retest-is-now-underway.html',\n",
       " 'https://www.cnbc.com/michael-santoli/',\n",
       " 'https://www.cnbc.com/2022/09/24/feared-stock-market-bottom-retest-is-now-underway.html',\n",
       " 'https://www.cnbc.com/michael-santoli/',\n",
       " 'https://www.cnbc.com/2022/09/24/liz-truss-britains-lurch-to-reaganomics-gets-thumbs-down-from-markets.html',\n",
       " 'https://www.cnbc.com/matt-clinch/',\n",
       " 'https://www.cnbc.com/2022/09/24/liz-truss-britains-lurch-to-reaganomics-gets-thumbs-down-from-markets.html',\n",
       " 'https://www.cnbc.com/matt-clinch/',\n",
       " 'https://www.cnbc.com/2022/09/24/convertible-sales-fall-in-us-amid-popularity-of-evs-suvs.html',\n",
       " 'https://www.cnbc.com/michael-wayland/',\n",
       " 'https://www.cnbc.com/2022/09/24/convertible-sales-fall-in-us-amid-popularity-of-evs-suvs.html',\n",
       " 'https://www.cnbc.com/michael-wayland/',\n",
       " 'https://www.cnbc.com/2022/09/24/top-10-cities-with-the-best-pizzerias-worldwide-.html',\n",
       " 'https://www.cnbc.com/2022/09/24/top-10-cities-with-the-best-pizzerias-worldwide-.html',\n",
       " 'https://www.cnbc.com/2022/09/24/how-to-raise-resilient-kids-by-developing-their-brains-with-nurturing-routines-parenting-expert.html',\n",
       " 'https://www.cnbc.com/2022/09/24/how-to-raise-resilient-kids-by-developing-their-brains-with-nurturing-routines-parenting-expert.html',\n",
       " 'https://www.cnbc.com/2022/09/21/big-businesses-trumpet-esg-credentials-scrutiny-is-on-the-rise.html',\n",
       " 'https://www.cnbc.com/anmar-frangoul-profile--cnbc/',\n",
       " 'https://www.cnbc.com/2022/09/21/big-businesses-trumpet-esg-credentials-scrutiny-is-on-the-rise.html',\n",
       " 'https://www.cnbc.com/anmar-frangoul-profile--cnbc/',\n",
       " 'https://www.cnbc.com/2022/09/23/inside-the-250-million-penthouse-on-billionaires-row.html',\n",
       " 'https://www.cnbc.com/robert-frank/',\n",
       " 'https://www.cnbc.com/2022/09/23/inside-the-250-million-penthouse-on-billionaires-row.html',\n",
       " 'https://www.cnbc.com/robert-frank/',\n",
       " 'https://www.cnbc.com/2022/09/22/diania-merriam-semi-retired-in-her-30s-now-she-works-7point5-hours-per-week.html',\n",
       " 'https://www.cnbc.com/nicolas-vega/',\n",
       " 'https://www.cnbc.com/2022/09/22/diania-merriam-semi-retired-in-her-30s-now-she-works-7point5-hours-per-week.html',\n",
       " 'https://www.cnbc.com/nicolas-vega/',\n",
       " 'https://www.cnbc.com/2022/09/23/tech-stocks-worst-two-week-stretch-since-the-start-of-pandemic.html',\n",
       " 'https://www.cnbc.com/ari-levy/',\n",
       " 'https://www.cnbc.com/2022/09/23/tech-stocks-worst-two-week-stretch-since-the-start-of-pandemic.html',\n",
       " 'https://www.cnbc.com/ari-levy/',\n",
       " 'https://www.cnbc.com/2022/09/23/british-pound-plunges-to-fresh-37-year-low-of-1point10-.html',\n",
       " 'https://www.cnbc.com/jenni-reid/',\n",
       " 'https://www.cnbc.com/2022/09/23/british-pound-plunges-to-fresh-37-year-low-of-1point10-.html',\n",
       " 'https://www.cnbc.com/jenni-reid/',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/09/24/quantum-investing-perils-and-promise-of-quantum-computing-are-nearing.html',\n",
       " 'https://www.cnbc.com/hugh-son/',\n",
       " 'https://www.cnbc.com/2022/09/24/quantum-investing-perils-and-promise-of-quantum-computing-are-nearing.html',\n",
       " 'https://www.cnbc.com/hugh-son/',\n",
       " 'https://www.cnbc.com/2022/09/23/elon-musk-direct-reports-at-tesla.html',\n",
       " 'https://www.cnbc.com/lora-kolodny/',\n",
       " 'https://www.cnbc.com/gabriel-cortes-bio/',\n",
       " 'https://www.cnbc.com/2022/09/23/elon-musk-direct-reports-at-tesla.html',\n",
       " 'https://www.cnbc.com/lora-kolodny/',\n",
       " 'https://www.cnbc.com/gabriel-cortes-bio/',\n",
       " 'https://www.cnbc.com/2022/09/23/mass-protests-in-iran-is-the-regimes-biggest-challenge-in-years.html',\n",
       " 'https://www.cnbc.com/natasha-turak/',\n",
       " 'https://www.cnbc.com/2022/09/23/mass-protests-in-iran-is-the-regimes-biggest-challenge-in-years.html',\n",
       " 'https://www.cnbc.com/natasha-turak/',\n",
       " 'https://www.cnbc.com/2022/09/23/uk-government-dishes-out-tax-cuts-as-country-braces-for-recession.html',\n",
       " 'https://www.cnbc.com/jenni-reid/',\n",
       " 'https://www.cnbc.com/2022/09/23/uk-government-dishes-out-tax-cuts-as-country-braces-for-recession.html',\n",
       " 'https://www.cnbc.com/jenni-reid/',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/09/23/stocks-could-continue-skittish-trading-until-interest-rate-move-calms-down.html',\n",
       " 'https://www.cnbc.com/patti-domm/',\n",
       " 'https://www.cnbc.com/2022/09/23/stocks-could-continue-skittish-trading-until-interest-rate-move-calms-down.html',\n",
       " 'https://www.cnbc.com/patti-domm/',\n",
       " 'https://www.cnbc.com/2022/09/23/hedge-funds-ramp-up-market-bets-as-volatility-brings-the-asset-class-back-into-favor.html',\n",
       " 'https://www.cnbc.com/yun-li/',\n",
       " 'https://www.cnbc.com/2022/09/23/hedge-funds-ramp-up-market-bets-as-volatility-brings-the-asset-class-back-into-favor.html',\n",
       " 'https://www.cnbc.com/yun-li/',\n",
       " '//www.cnbc.com/us-market-movers/',\n",
       " '/us-market-movers/',\n",
       " '/stocks/',\n",
       " 'https://www.cnbc.com/2022/09/23/stocks-could-continue-skittish-trading-until-interest-rate-move-calms-down.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/patti-domm/',\n",
       " 'https://www.cnbc.com/2022/09/22/futures-inch-higher-following-another-day-of-losses-after-fed-rate-hike-sell-offs.html',\n",
       " 'https://www.cnbc.com/samantha-subin/',\n",
       " 'https://www.cnbc.com/alex-harring/',\n",
       " 'https://www.cnbc.com/2022/09/23/10-year-treasury-yield-falls-as-markets-digest-fed-rate-hike.html',\n",
       " 'https://www.cnbc.com/samantha-subin/',\n",
       " 'https://www.cnbc.com/sophie-kiderlin/',\n",
       " 'https://www.cnbc.com/2022/09/23/from-the-fed-to-europes-currency-crisis-heres-whats-behind-this-selloff-in-financial-markets.html',\n",
       " 'https://www.cnbc.com/patti-domm/',\n",
       " '//www.cnbc.com/live-tv/',\n",
       " '//www.cnbc.com/latest-video/',\n",
       " 'https://www.cnbc.com/video/2022/09/22/how-these-startups-are-fixing-water-waste-on-farms.html',\n",
       " 'https://www.cnbc.com/video/2022/09/20/why-layoffs-may-be-on-the-horizon-in-the-us.html',\n",
       " 'https://www.cnbc.com/video/2022/09/23/the-fed-will-have-to-take-the-terminal-funds-rate-higher-in-23-says-former-kc-fed-president.html',\n",
       " 'https://www.cnbc.com/special-reports/',\n",
       " 'https://www.cnbc.com/2022/09/23/google-ceo-pichai-fields-questions-on-cost-cuts-at-all-hands-meeting-.html',\n",
       " 'https://www.cnbc.com/2022/09/24/how-to-raise-resilient-kids-by-developing-their-brains-with-nurturing-routines-parenting-expert.html',\n",
       " 'https://www.cnbc.com/2022/09/22/diania-merriam-semi-retired-in-her-30s-now-she-works-7point5-hours-per-week.html',\n",
       " 'https://www.cnbc.com/2022/09/21/inflation-relief-checks-residents-in-17-states-could-get-money-soon.html',\n",
       " 'https://www.cnbc.com/2022/09/23/elon-musk-direct-reports-at-tesla.html',\n",
       " 'https://www.cnbc.com/pro/news/',\n",
       " 'https://www.cnbc.com/2022/09/24/analysts-name-top-high-conviction-stocks-for-playing-market-turbulence.html',\n",
       " 'https://www.cnbc.com/2022/09/24/analysts-name-top-high-conviction-stocks-for-playing-market-turbulence.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/michael-bloom/',\n",
       " 'https://www.cnbc.com/2022/09/24/feared-stock-market-bottom-retest-is-now-underway.html',\n",
       " 'https://www.cnbc.com/2022/09/24/feared-stock-market-bottom-retest-is-now-underway.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/michael-santoli/',\n",
       " 'https://www.cnbc.com/2022/09/24/quantum-investing-perils-and-promise-of-quantum-computing-are-nearing.html',\n",
       " 'https://www.cnbc.com/2022/09/24/quantum-investing-perils-and-promise-of-quantum-computing-are-nearing.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/hugh-son/',\n",
       " 'https://www.cnbc.com/2022/09/23/stocks-could-continue-skittish-trading-until-interest-rate-move-calms-down.html',\n",
       " 'https://www.cnbc.com/2022/09/23/stocks-could-continue-skittish-trading-until-interest-rate-move-calms-down.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/patti-domm/',\n",
       " 'https://www.cnbc.com/2022/09/23/pro-picks-watch-all-of-fridays-big-stock-calls-on-cnbc.html',\n",
       " 'https://www.cnbc.com/2022/09/23/pro-picks-watch-all-of-fridays-big-stock-calls-on-cnbc.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/joshua-natoli/',\n",
       " 'https://www.cnbc.com/sustainable-future/',\n",
       " 'https://www.cnbc.com/2022/09/21/big-businesses-trumpet-esg-credentials-scrutiny-is-on-the-rise.html',\n",
       " 'https://www.cnbc.com/2022/09/21/big-businesses-trumpet-esg-credentials-scrutiny-is-on-the-rise.html',\n",
       " 'https://www.cnbc.com/anmar-frangoul-profile--cnbc/',\n",
       " 'https://www.cnbc.com/2022/09/20/uns-guterres-says-polluters-must-pay-calls-for-tax-on-fossil-fuels.html',\n",
       " 'https://www.cnbc.com/2022/09/20/uns-guterres-says-polluters-must-pay-calls-for-tax-on-fossil-fuels.html',\n",
       " 'https://www.cnbc.com/anmar-frangoul-profile--cnbc/',\n",
       " 'https://www.cnbc.com/2022/09/07/uks-new-energy-chief-says-fracking-interesting-we-need-fossil-fuels.html',\n",
       " 'https://www.cnbc.com/2022/09/07/uks-new-energy-chief-says-fracking-interesting-we-need-fossil-fuels.html',\n",
       " 'https://www.cnbc.com/anmar-frangoul-profile--cnbc/',\n",
       " 'https://www.cnbc.com/video/2022/09/08/undps-human-development-report-uncertain-times-unsettled-lives.html',\n",
       " 'https://www.cnbc.com/video/2022/09/08/undps-human-development-report-uncertain-times-unsettled-lives.html',\n",
       " 'https://www.cnbc.com/tania-bryer/',\n",
       " 'https://www.cnbc.com/2022/09/01/huge-offshore-wind-farm-hornsea-2-is-fully-operational-orsted-says.html',\n",
       " 'https://www.cnbc.com/2022/09/01/huge-offshore-wind-farm-hornsea-2-is-fully-operational-orsted-says.html',\n",
       " 'https://www.cnbc.com/anmar-frangoul-profile--cnbc/',\n",
       " 'https://www.cnbc.com/coronavirus/',\n",
       " 'https://www.cnbc.com/2022/09/23/moderna-asks-fda-to-authorize-omicron-covid-boosters-for-children-as-young-as-6-years-old.html',\n",
       " 'https://www.cnbc.com/2022/09/23/moderna-asks-fda-to-authorize-omicron-covid-boosters-for-children-as-young-as-6-years-old.html',\n",
       " 'https://www.cnbc.com/spencer-kimball/',\n",
       " 'https://www.cnbc.com/2022/09/22/who-warns-ability-to-identify-new-covid-variants-is-diminishing-as-testing-declines-.html',\n",
       " 'https://www.cnbc.com/2022/09/22/who-warns-ability-to-identify-new-covid-variants-is-diminishing-as-testing-declines-.html',\n",
       " 'https://www.cnbc.com/spencer-kimball/',\n",
       " 'https://www.cnbc.com/2022/09/21/watch-ukrainian-president-zelenskyy-addresses-un-general-assembly.html',\n",
       " 'https://www.cnbc.com/2022/09/21/watch-ukrainian-president-zelenskyy-addresses-un-general-assembly.html',\n",
       " 'https://www.cnbc.com/2022/09/21/what-another-major-rate-hike-by-the-federal-reserve-means-to-you.html',\n",
       " 'https://www.cnbc.com/2022/09/21/what-another-major-rate-hike-by-the-federal-reserve-means-to-you.html',\n",
       " 'https://www.cnbc.com/jessica-dickler/',\n",
       " 'https://www.cnbc.com/2022/09/20/layoffs-loom-on-the-horizon-some-economists-say.html',\n",
       " 'https://www.cnbc.com/2022/09/20/layoffs-loom-on-the-horizon-some-economists-say.html',\n",
       " 'https://www.cnbc.com/andrea-miller/',\n",
       " 'https://www.cnbc.com/cnbc-travel/',\n",
       " 'https://www.cnbc.com/2022/09/22/what-are-the-most-common-crimes-in-hotels-not-theft-say-uk-police-.html',\n",
       " 'https://www.cnbc.com/2022/09/22/what-are-the-most-common-crimes-in-hotels-not-theft-say-uk-police-.html',\n",
       " 'https://www.cnbc.com/jenni-reid/',\n",
       " 'https://www.cnbc.com/2022/09/19/how-much-does-it-cost-to-visit-bhutan-200-a-day-plus-travel-costs-.html',\n",
       " 'https://www.cnbc.com/2022/09/19/how-much-does-it-cost-to-visit-bhutan-200-a-day-plus-travel-costs-.html',\n",
       " 'https://www.cnbc.com/monica-pitrelli/',\n",
       " 'https://www.cnbc.com/2022/09/16/woman-ochre-de-koonings-painting-from-theft-to-its-return-home.html',\n",
       " 'https://www.cnbc.com/2022/09/16/woman-ochre-de-koonings-painting-from-theft-to-its-return-home.html',\n",
       " 'https://www.cnbc.com/monica-pitrelli/',\n",
       " 'https://www.cnbc.com/2022/09/12/best-hotels-for-business-travelers-in-asia-pacific.html',\n",
       " 'https://www.cnbc.com/2022/09/12/best-hotels-for-business-travelers-in-asia-pacific.html',\n",
       " 'https://www.cnbc.com/monica-pitrelli/',\n",
       " 'https://www.cnbc.com/2022/09/09/where-russians-go-on-vacation-since-the-ukraine-war-started.html',\n",
       " 'https://www.cnbc.com/2022/09/09/where-russians-go-on-vacation-since-the-ukraine-war-started.html',\n",
       " 'https://www.cnbc.com/lee-ying-shan/',\n",
       " 'https://www.cnbc.com/make-it/',\n",
       " 'https://www.cnbc.com/2022/09/24/three-rules-for-a-successful-open-relationship.html',\n",
       " 'https://www.cnbc.com/2022/09/24/three-rules-for-a-successful-open-relationship.html',\n",
       " 'https://www.cnbc.com/aditi-shrikant-bio/',\n",
       " 'https://www.cnbc.com/2022/09/24/top-10-cities-with-the-best-pizzerias-worldwide-.html',\n",
       " 'https://www.cnbc.com/2022/09/24/top-10-cities-with-the-best-pizzerias-worldwide-.html',\n",
       " 'https://www.cnbc.com/celia-fernandez/',\n",
       " 'https://www.cnbc.com/2022/09/24/easy-meals-for-two-under-20-from-black-girls-in-trader-joes-creator.html',\n",
       " 'https://www.cnbc.com/2022/09/24/easy-meals-for-two-under-20-from-black-girls-in-trader-joes-creator.html',\n",
       " 'https://www.cnbc.com/renee-onque/',\n",
       " 'https://www.cnbc.com/2022/09/24/how-to-raise-resilient-kids-by-developing-their-brains-with-nurturing-routines-parenting-expert.html',\n",
       " 'https://www.cnbc.com/2022/09/24/how-to-raise-resilient-kids-by-developing-their-brains-with-nurturing-routines-parenting-expert.html',\n",
       " 'https://www.cnbc.com/dr-dana-suskind/',\n",
       " 'https://www.cnbc.com/2022/09/24/queer-eyes-karamo-brown-shares-morning-routine.html',\n",
       " 'https://www.cnbc.com/2022/09/24/queer-eyes-karamo-brown-shares-morning-routine.html',\n",
       " 'https://www.cnbc.com/ashton-jackson/',\n",
       " 'https://www.cnbc.com/investing-in-supertrends/',\n",
       " 'https://www.cnbc.com/2022/08/18/web3-is-in-chaos-metaverses-in-walled-gardens-randi-zuckerberg.html',\n",
       " 'https://www.cnbc.com/2022/08/18/web3-is-in-chaos-metaverses-in-walled-gardens-randi-zuckerberg.html',\n",
       " 'https://www.cnbc.com/goh-chiew-tong/',\n",
       " 'https://www.cnbc.com/2022/08/17/japan-support-for-nuclear-restart-is-highest-since-fukushima-disaster.html',\n",
       " 'https://www.cnbc.com/2022/08/17/japan-support-for-nuclear-restart-is-highest-since-fukushima-disaster.html',\n",
       " 'https://www.cnbc.com/lee-ying-shan/',\n",
       " 'https://www.cnbc.com/2022/08/10/india-australia-singapore-firms-jobs-are-in-these-sectors-linkedin.html',\n",
       " 'https://www.cnbc.com/2022/08/10/india-australia-singapore-firms-jobs-are-in-these-sectors-linkedin.html',\n",
       " 'https://www.cnbc.com/charmaine-jacob/',\n",
       " 'https://www.cnbc.com/2022/08/08/baidus-robotaxis-dont-need-any-human-staff-in-these-parts-of-china.html',\n",
       " 'https://www.cnbc.com/2022/08/08/baidus-robotaxis-dont-need-any-human-staff-in-these-parts-of-china.html',\n",
       " 'https://www.cnbc.com/evelyn-cheng/',\n",
       " 'https://www.cnbc.com/2021/07/26/action-on-climate-change-can-boost-global-economy-economist-says.html',\n",
       " 'https://www.cnbc.com/2021/07/26/action-on-climate-change-can-boost-global-economy-economist-says.html',\n",
       " '//www.cnbc.com',\n",
       " '//www.cnbc.com/application/pro/?__source=pro|globalfooter/',\n",
       " '//www.cnbc.com/cnbc-reprints/',\n",
       " 'https://www.cnbccouncils.com/',\n",
       " 'https://corporate.comcast.com/values/integrity',\n",
       " 'https://www.peacocktv.com/?cid=20200101evergreensymdisp009&utm_source=cnbc&utm_medium=symphony_editorial_brandawareness_footerlink&utm_campaign=20200101evergreen&utm_term=na&utm_content=na_na/',\n",
       " 'https://cnbcrsh.qualtrics.com/jfe/form/SV_8v2FqPLC71m5Gaq?Origin=cnbc',\n",
       " '//www.cnbc.com/digital-products/',\n",
       " '//www.cnbc.com/cnbc-news-releases/',\n",
       " '//www.cnbc.com/closed-captioning/',\n",
       " '//www.cnbc.com/corrections/',\n",
       " '//www.cnbc.com/about-cnbc-international/',\n",
       " '//www.cnbc.com/cnbc-internship-program/',\n",
       " '//www.cnbc.com/site-map/',\n",
       " 'https://www.nbcuniversal.com/privacy/cookies#cookie_management',\n",
       " '//www.cnbc.com/cnbc-careers-and-employment/',\n",
       " 'https://help.cnbc.com/',\n",
       " 'https://help.cnbc.com/contact/',\n",
       " 'https://www.facebook.com/cnbcinternational/c/',\n",
       " 'https://www.twitter.com/cnbci?lang=en/',\n",
       " 'https://www.linkedin.com/showcase/cnbc-international/',\n",
       " 'https://www.instagram.com/cnbcinternational/?hl=en/',\n",
       " 'https://www.youtube.com/user/CNBCInternational/',\n",
       " 'https://apple.news/T3OtoXcxtRkuHRkM7SpFP_Q',\n",
       " '//www.cnbc.com/rss-feeds/',\n",
       " '//www.cnbc.com/news-tips/',\n",
       " 'https://together.nbcuni.com/advertise/?utm_source=cnbc&utm_medium=referral&utm_campaign=property_ad_pages',\n",
       " '//www.cnbc.com/sign-up-for-cnbc-newsletters/',\n",
       " 'https://www.nbcuniversal.com/privacy?intake=CNBC',\n",
       " 'https://www.nbcuniversal.com/privacy/notrtoo?intake=CNBC',\n",
       " 'https://www.nbcuniversal.com/privacy/california-consumer-privacy-act?intake=CNBC',\n",
       " '/nbcuniversal-terms-of-service/',\n",
       " 'https://www.nbcuniversal.com',\n",
       " '/market-data-terms-of-service/',\n",
       " '//www.cnbc.com/market-data-terms-of-service/']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap news link\n",
    "\n",
    "link = []  #empty list\n",
    "\n",
    "for i in soup9.find_all('a'):\n",
    "    link.append(i.get('href'))\n",
    "    \n",
    "link\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3371f569",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05169d01",
   "metadata": {},
   "source": [
    "Scrape below mentioned details :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2610015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "articles = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "055773b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ccc3bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup10 = BeautifulSoup(articles.content)\n",
    "#print(soup10.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146ece5",
   "metadata": {},
   "source": [
    "i) Paper Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85f3a7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reward is enough',\n",
       " 'Making sense of raw input',\n",
       " 'Law and logic: A review from an argumentation perspective',\n",
       " 'Creativity and artificial intelligence',\n",
       " 'Artificial cognition for social human–robot interaction: An implementation',\n",
       " 'Explanation in artificial intelligence: Insights from the social sciences',\n",
       " 'Making sense of sensory input',\n",
       " 'Conflict-based search for optimal multi-agent pathfinding',\n",
       " 'Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning',\n",
       " 'The Hanabi challenge: A new frontier for AI research',\n",
       " 'Evaluating XAI: A comparison of rule-based and example-based explanations',\n",
       " 'Argumentation in artificial intelligence',\n",
       " 'Algorithms for computing strategies in two-player simultaneous move games',\n",
       " 'Multiple object tracking: A literature review',\n",
       " 'Selection of relevant features and examples in machine learning',\n",
       " 'A survey of inverse reinforcement learning: Challenges, methods and progress',\n",
       " 'Explaining individual predictions when features are dependent: More accurate approximations to Shapley values',\n",
       " 'A review of possible effects of cognitive biases on interpretation of rule-based machine learning models',\n",
       " 'Integrating social power into the decision-making of cognitive agents',\n",
       " \"“That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\",\n",
       " 'Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies',\n",
       " 'Algorithm runtime prediction: Methods & evaluation',\n",
       " 'Wrappers for feature subset selection',\n",
       " 'Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics',\n",
       " 'Quantum computation, quantum theory and AI']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap article title\n",
    "\n",
    "p_title = []  #empty list\n",
    "\n",
    "for i in soup10.find_all('h2', class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    p_title.append(i.text)\n",
    "    \n",
    "p_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3e9ff",
   "metadata": {},
   "source": [
    "ii) Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8611017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Silver, David, Singh, Satinder, Precup, Doina, Sutton, Richard S. ',\n",
       " 'Evans, Richard, Bošnjak, Matko and 5 more',\n",
       " 'Prakken, Henry, Sartor, Giovanni ',\n",
       " 'Boden, Margaret A. ',\n",
       " 'Lemaignan, Séverin, Warnier, Mathieu and 3 more',\n",
       " 'Miller, Tim ',\n",
       " 'Evans, Richard, Hernández-Orallo, José and 3 more',\n",
       " 'Sharon, Guni, Stern, Roni, Felner, Ariel, Sturtevant, Nathan R. ',\n",
       " 'Sutton, Richard S., Precup, Doina, Singh, Satinder ',\n",
       " 'Bard, Nolan, Foerster, Jakob N. and 13 more',\n",
       " 'van der Waa, Jasper, Nieuwburg, Elisabeth, Cremers, Anita, Neerincx, Mark ',\n",
       " 'Bench-Capon, T.J.M., Dunne, Paul E. ',\n",
       " 'Bošanský, Branislav, Lisý, Viliam and 3 more',\n",
       " 'Luo, Wenhan, Xing, Junliang and 4 more',\n",
       " 'Blum, Avrim L., Langley, Pat ',\n",
       " 'Arora, Saurabh, Doshi, Prashant ',\n",
       " 'Aas, Kjersti, Jullum, Martin, Løland, Anders ',\n",
       " 'Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Johannes ',\n",
       " 'Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. ',\n",
       " 'Riveiro, Maria, Thill, Serge ',\n",
       " 'Kenny, Eoin M., Ford, Courtney, Quinn, Molly, Keane, Mark T. ',\n",
       " 'Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyton-Brown, Kevin ',\n",
       " 'Kohavi, Ron, John, George H. ',\n",
       " 'Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srikrishna ',\n",
       " 'Ying, Mingsheng ']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap authors name\n",
    "\n",
    "authors = []  #empty list\n",
    "\n",
    "for i in soup10.find_all('span', class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    authors.append(i.text)\n",
    "    \n",
    "authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e3b25",
   "metadata": {},
   "source": [
    "iii) Published Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8953c551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['October 2021',\n",
       " 'October 2021',\n",
       " 'October 2015',\n",
       " 'August 1998',\n",
       " 'June 2017',\n",
       " 'February 2019',\n",
       " 'April 2021',\n",
       " 'February 2015',\n",
       " 'August 1999',\n",
       " 'March 2020',\n",
       " 'February 2021',\n",
       " 'October 2007',\n",
       " 'August 2016',\n",
       " 'April 2021',\n",
       " 'December 1997',\n",
       " 'August 2021',\n",
       " 'September 2021',\n",
       " 'June 2021',\n",
       " 'December 2016',\n",
       " 'September 2021',\n",
       " 'May 2021',\n",
       " 'January 2014',\n",
       " 'December 1997',\n",
       " 'October 2021',\n",
       " 'February 2010']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap Published Date\n",
    "\n",
    "pub_date = []  #empty list\n",
    "\n",
    "for i in soup10.find_all('span',class_=\"sc-1thf9ly-2 bKddwo\" ):\n",
    "    pub_date.append(i.text)\n",
    "    \n",
    "pub_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f86b7b",
   "metadata": {},
   "source": [
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "68c2ac0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#skip-to-content-anchor'],\n",
       " ['http://www.elsevier.com'],\n",
       " ['https://account.elsevier.com/auth'],\n",
       " ['https://elsevier.com/about'],\n",
       " ['https://www.elsevier.com/connect'],\n",
       " ['https://www.elsevier.com/about/careers'],\n",
       " ['https://elsevier.com/about'],\n",
       " ['https://www.elsevier.com/connect'],\n",
       " ['https://www.elsevier.com/about/careers'],\n",
       " ['https://www.elsevier.com/rd-solutions'],\n",
       " ['https://www.elsevier.com/clinical-solutions'],\n",
       " ['https://www.elsevier.com/research-platforms'],\n",
       " ['https://www.elsevier.com/research-intelligence'],\n",
       " ['https://www.elsevier.com/education'],\n",
       " ['https://www.elsevier.com/solutions'],\n",
       " ['https://www.elsevier.com/rd-solutions'],\n",
       " ['https://www.elsevier.com/clinical-solutions'],\n",
       " ['https://www.elsevier.com/research-platforms'],\n",
       " ['https://www.elsevier.com/research-intelligence'],\n",
       " ['https://www.elsevier.com/education'],\n",
       " ['https://www.elsevier.com/solutions'],\n",
       " ['https://www.elsevier.com/authors'],\n",
       " ['https://www.elsevier.com/editors'],\n",
       " ['https://www.elsevier.com/reviewers'],\n",
       " ['https://www.elsevier.com/librarians'],\n",
       " ['https://www.elsevier.com/strategic-partners'],\n",
       " ['https://www.elsevier.com/open-access'],\n",
       " ['https://www.elsevier.com/societies'],\n",
       " ['https://www.elsevier.com/authors'],\n",
       " ['https://www.elsevier.com/editors'],\n",
       " ['https://www.elsevier.com/reviewers'],\n",
       " ['https://www.elsevier.com/librarians'],\n",
       " ['https://www.elsevier.com/strategic-partners'],\n",
       " ['https://www.elsevier.com/open-access'],\n",
       " ['https://www.elsevier.com/societies'],\n",
       " ['https://www.elsevier.com/books-and-journals'],\n",
       " ['https://webshop.elsevier.com/?utm_source=ecom&utm_medium=top&utm_campaign=webshop'],\n",
       " ['https://www.elsevier.com/books-and-journals'],\n",
       " ['https://webshop.elsevier.com/?utm_source=ecom&utm_medium=top&utm_campaign=webshop'],\n",
       " ['https://global-checkout.elsevier.com'],\n",
       " ['https://account.elsevier.com/auth'],\n",
       " ['https://www.sciencedirect.com/science/journal/00043702'],\n",
       " ['https://www.editorialmanager.com/artint/default.aspx'],\n",
       " ['https://www.elsevier.com/'],\n",
       " ['https://www.elsevier.com/search-results?labels=journals'],\n",
       " ['/artificial-intelligence'],\n",
       " ['/artificial-intelligence/most-downloaded-articles'],\n",
       " ['https://www.sciencedirect.com/science/journal/00043702'],\n",
       " ['https://www.editorialmanager.com/artint/default.aspx'],\n",
       " ['https://www.sciencedirect.com/science/journal/00043702'],\n",
       " ['https://www.elsevier.com/journals/artificial-intelligence/0004-3702/guide-for-authors'],\n",
       " ['https://www.editorialmanager.com/artint/default.aspx'],\n",
       " ['https://authors.elsevier.com/tracking/landingpage/selection.do'],\n",
       " ['https://www.elsevier.com/journals/artificial-intelligence/0004-3702/subscribe?subscriptiontype=institutional'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370221000862'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370221000722'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370215000910'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370298000551'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370216300790'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370218305988'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370220301855'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370214001386'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370299000521'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370219300116'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370220301533'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370207000793'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370216300285'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370220301958'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370297000635'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370221000515'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370221000539'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370221000096'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370216300868'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370221000588'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370221000102'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370213001082'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S000437029700043X'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370221000734'],\n",
       " ['https://www.sciencedirect.com/science/article/pii/S0004370209001398'],\n",
       " ['https://www.sciencedirect.com/science/journal/00043702'],\n",
       " ['https://www.sciencedirect.com/user/alerts'],\n",
       " ['https://www.sciencedirect.com/user/register?utm_campaign=sd_recommender_ELSJLS&utm_channel=elseco&dgcid=sd_recommender_ELSJLS'],\n",
       " ['http://www.elsevier.com/authors/home'],\n",
       " ['https://www.editorialmanager.com/artint/default.aspx'],\n",
       " ['https://www.editorialmanager.com/artint/default.aspx'],\n",
       " ['https://researcheracademy.elsevier.com'],\n",
       " ['https://www.elsevier.com/about/policies/copyright/permissions'],\n",
       " ['https://webshop.elsevier.com'],\n",
       " ['https://service.elsevier.com/app/home/supporthub/publishing/#authors'],\n",
       " ['https://authors.elsevier.com/tracking/landingpage/selection.do'],\n",
       " ['https://www.elsevier.com/librarians'],\n",
       " ['https://www.elsevier.com/journals/artificial-intelligence/0004-3702/subscribe?subscriptiontype=institutional'],\n",
       " ['http://www.elsevier.com/editors'],\n",
       " ['http://www.elsevier.com/editors/perk'],\n",
       " ['https://www.elsevier.com/editors/guest-editors'],\n",
       " ['https://service.elsevier.com/app/home/supporthub/publishing/#editors'],\n",
       " ['http://www.elsevier.com/reviewers'],\n",
       " ['https://www.elsevier.com/reviewers/how-to-review'],\n",
       " ['https://www.editorialmanager.com/artint/default.aspx'],\n",
       " ['https://www.elsevier.com/reviewers/becoming-a-reviewer-how-and-why#recognizing'],\n",
       " ['https://service.elsevier.com/app/home/supporthub/publishing/#reviewers'],\n",
       " ['https://www.elsevier.com'],\n",
       " ['//www.elsevier.com/legal/elsevier-website-terms-and-conditions'],\n",
       " ['//www.elsevier.com/legal/privacy-policy'],\n",
       " ['//www.elsevier.com/legal/cookienotice'],\n",
       " ['//www.elsevier.com/sitemap'],\n",
       " ['https://www.relx.com/']]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap url\n",
    "\n",
    "url = []  #empty list\n",
    "\n",
    "for i in soup10.find_all('a'):\n",
    "    url.append(i.get('href').split())\n",
    "    \n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f906d1d",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f12ee7",
   "metadata": {},
   "source": [
    "i) Restaurant name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "08bfdcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "resaurant_page = requests.get('https://www.dineout.co.in/delhi-restaurants/welcome-back')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e124b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resaurant_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "164572e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup11 = BeautifulSoup(resaurant_page.content)\n",
    "#print(soup11.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "824a366f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Tamasha'],\n",
       " ['Local'],\n",
       " ['Openhouse', 'Cafe'],\n",
       " ['Station', 'Bar'],\n",
       " ['Ministry', 'Of', 'Beer'],\n",
       " ['QBA'],\n",
       " ['The', 'G.T.', 'ROAD'],\n",
       " ['The', 'Junkyard', 'Cafe'],\n",
       " [\"Berco's\"],\n",
       " ['Connaught', 'Clubhouse', 'Microbrewery'],\n",
       " ['Farzi', 'Cafe'],\n",
       " ['My', 'Bar', 'Headquarters'],\n",
       " ['Chido'],\n",
       " ['Unplugged', 'Courtyard'],\n",
       " ['Ardor', '2.1', 'Restaurant', 'and', 'Lounge'],\n",
       " ['38', 'Barracks'],\n",
       " ['Sandoz'],\n",
       " ['The', 'Luggage', 'Room', 'By', 'Sandoz'],\n",
       " ['Out', 'Of', 'The', 'Box', 'Courtyard'],\n",
       " [\"Chili's\", 'American', 'Grill', 'and', 'Bar'],\n",
       " ['Ghoomar', 'Traditional', 'Thali', 'Restaurant']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap Restaurant Names\n",
    "\n",
    "res_name = []  #empty list\n",
    "\n",
    "for i in soup11.find_all('a', class_ =\"restnt-name ellipsis\"):\n",
    "    res_name.append(i.text.split())\n",
    "    \n",
    "res_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b2d10",
   "metadata": {},
   "source": [
    "ii) Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b0c24ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Continental, Asian, Italian, North Indian',\n",
       " ' North Indian, Asian, Continental',\n",
       " ' North Indian, Asian, Italian',\n",
       " ' Italian, Chinese, North Indian, Fast Food',\n",
       " ' North Indian, Continental, American, Asian',\n",
       " ' North Indian, Continental, Italian',\n",
       " ' North Indian',\n",
       " ' North Indian, Continental, Chinese, Fast Food',\n",
       " ' Chinese, Thai',\n",
       " ' North Indian, Continental, Asian, Chinese',\n",
       " ' Modern Indian, Continental, Finger Food',\n",
       " ' North Indian, Chinese',\n",
       " ' North Indian, Italian, Continental, Asian, Finger Food',\n",
       " ' North Indian, Italian, Chinese, Turkish, Continental',\n",
       " ' North Indian, Chinese, Italian, Continental',\n",
       " ' North Indian, Chinese, Continental',\n",
       " ' North Indian, Chinese, Continental',\n",
       " ' Chinese, Italian, North Indian, Continental',\n",
       " ' North Indian, Mediterranean, Chinese, Italian',\n",
       " ' Mexican, American, Tex Mex',\n",
       " ' North Indian, Rajasthani']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap Restaurant Cuisines\n",
    "\n",
    "res_cuisines = []  #empty list\n",
    "\n",
    "for i in soup11.find_all('span', class_=\"double-line-ellipsis\"):\n",
    "    res_cuisines.append(i.text.split('|')[-1])\n",
    "    \n",
    "res_cuisines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1a9f0",
   "metadata": {},
   "source": [
    "iii) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c290b85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Connaught Place, Central Delhi',\n",
       " 'Scindia House,Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'F-Block,Connaught Place, Central Delhi',\n",
       " 'M-Block,Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'M-Block,Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'M-Block,Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'M-Block,Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi',\n",
       " 'M-Block,Connaught Place, Central Delhi',\n",
       " 'Connaught Place, Central Delhi']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrap restaurant location\n",
    "\n",
    "res_location = []  #empty list\n",
    "\n",
    "for i in soup11.find_all('div', class_=\"restnt-loc ellipsis\"):\n",
    "    res_location.append(i.text)\n",
    "    \n",
    "res_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f59fab",
   "metadata": {},
   "source": [
    "iv) Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5237e577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.2',\n",
       " '4',\n",
       " '4.1',\n",
       " '4.1',\n",
       " '4',\n",
       " '4.3',\n",
       " '4.3',\n",
       " '4.1',\n",
       " '4.3',\n",
       " '4.2',\n",
       " '4.1',\n",
       " '4',\n",
       " '4.2',\n",
       " '4',\n",
       " '3.8',\n",
       " '4.3',\n",
       " '4',\n",
       " '3.9',\n",
       " '4.1',\n",
       " '4.3',\n",
       " '4.1']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrap restaurant rating\n",
    "\n",
    "res_rating = []  #empty list\n",
    "\n",
    "for i in soup11.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    res_rating.append(i.text)\n",
    "    \n",
    "res_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77826c88",
   "metadata": {},
   "source": [
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "aa00c626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/a/j/p20996-145631488756cd9a0796608.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/b/t/p27452-15020105505986dcb6d147f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/j/y/p19748-16474299906231c96621c58.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/9/i/b/p971-165909823762e3d47db6d56.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/a/d/p32381-1495943585592a49a166fe7.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/e/e/p29906-16183962346076c44ac433d.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/m/u/p31393-15972091555f337a43bb961.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/h/p/p20298-1447661865564991294ad1b.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/t/u/p237-16468990666229af7a72b08.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/c/z/p77626-15833232035e5f98437554f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/y/y/p4199-164188203361dd21b1a3174.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/d/f/p19636-16463919576221f295ae1f1.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/9/u/d/p97184-1648026866623ae4f24ea25.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/u/y/p20941-15700828565d959028e9f28.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/y/m/p221-16455303976214cd1d7a086.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/y/j/p21171-166019927162f4a167b10af.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/e/u/p80493-16064603115fc0a397716de.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/b/u/p23048-1477373818580eef7a04d08.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/x/t/p83921-16017104805f782990b9b0c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/r/w/p31397-164157705861d87a6224564.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/e/z/p53380-15544492915ca7038b700f1.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrap restaurant image url\n",
    "\n",
    "res_img_url = []  #empty list\n",
    "\n",
    "for i in soup11.find_all('img', class_=\"no-img\"):\n",
    "    res_img_url.append(i.get('data-src'))\n",
    "    \n",
    "res_img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6a354231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 21 21 21 21\n"
     ]
    }
   ],
   "source": [
    "# print length\n",
    "print(len(res_name), len(res_cuisines), len(res_location), len(res_rating), len(res_img_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c8faf",
   "metadata": {},
   "source": [
    "MAKING DATA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bca79096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "baf262d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame({'RESTAURANT_NAME':res_name, 'CUISINES':res_cuisines, 'LOCATION':res_location,    'RATING':res_rating, 'IMG_URL':res_img_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2feeed68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESTAURANT_NAME</th>\n",
       "      <th>CUISINES</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>RATING</th>\n",
       "      <th>IMG_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Tamasha]</td>\n",
       "      <td>Continental, Asian, Italian, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Local]</td>\n",
       "      <td>North Indian, Asian, Continental</td>\n",
       "      <td>Scindia House,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Openhouse, Cafe]</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Station, Bar]</td>\n",
       "      <td>Italian, Chinese, North Indian, Fast Food</td>\n",
       "      <td>F-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Ministry, Of, Beer]</td>\n",
       "      <td>North Indian, Continental, American, Asian</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[QBA]</td>\n",
       "      <td>North Indian, Continental, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[The, G.T., ROAD]</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[The, Junkyard, Cafe]</td>\n",
       "      <td>North Indian, Continental, Chinese, Fast Food</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Berco's]</td>\n",
       "      <td>Chinese, Thai</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Connaught, Clubhouse, Microbrewery]</td>\n",
       "      <td>North Indian, Continental, Asian, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Farzi, Cafe]</td>\n",
       "      <td>Modern Indian, Continental, Finger Food</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[My, Bar, Headquarters]</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Chido]</td>\n",
       "      <td>North Indian, Italian, Continental, Asian, Fi...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Unplugged, Courtyard]</td>\n",
       "      <td>North Indian, Italian, Chinese, Turkish, Cont...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[Ardor, 2.1, Restaurant, and, Lounge]</td>\n",
       "      <td>North Indian, Chinese, Italian, Continental</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[38, Barracks]</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[Sandoz]</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[The, Luggage, Room, By, Sandoz]</td>\n",
       "      <td>Chinese, Italian, North Indian, Continental</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[Out, Of, The, Box, Courtyard]</td>\n",
       "      <td>North Indian, Mediterranean, Chinese, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[Chili's, American, Grill, and, Bar]</td>\n",
       "      <td>Mexican, American, Tex Mex</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[Ghoomar, Traditional, Thali, Restaurant]</td>\n",
       "      <td>North Indian, Rajasthani</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              RESTAURANT_NAME  \\\n",
       "0                                   [Tamasha]   \n",
       "1                                     [Local]   \n",
       "2                           [Openhouse, Cafe]   \n",
       "3                              [Station, Bar]   \n",
       "4                        [Ministry, Of, Beer]   \n",
       "5                                       [QBA]   \n",
       "6                           [The, G.T., ROAD]   \n",
       "7                       [The, Junkyard, Cafe]   \n",
       "8                                   [Berco's]   \n",
       "9        [Connaught, Clubhouse, Microbrewery]   \n",
       "10                              [Farzi, Cafe]   \n",
       "11                    [My, Bar, Headquarters]   \n",
       "12                                    [Chido]   \n",
       "13                     [Unplugged, Courtyard]   \n",
       "14      [Ardor, 2.1, Restaurant, and, Lounge]   \n",
       "15                             [38, Barracks]   \n",
       "16                                   [Sandoz]   \n",
       "17           [The, Luggage, Room, By, Sandoz]   \n",
       "18             [Out, Of, The, Box, Courtyard]   \n",
       "19       [Chili's, American, Grill, and, Bar]   \n",
       "20  [Ghoomar, Traditional, Thali, Restaurant]   \n",
       "\n",
       "                                             CUISINES  \\\n",
       "0           Continental, Asian, Italian, North Indian   \n",
       "1                    North Indian, Asian, Continental   \n",
       "2                        North Indian, Asian, Italian   \n",
       "3           Italian, Chinese, North Indian, Fast Food   \n",
       "4          North Indian, Continental, American, Asian   \n",
       "5                  North Indian, Continental, Italian   \n",
       "6                                        North Indian   \n",
       "7       North Indian, Continental, Chinese, Fast Food   \n",
       "8                                       Chinese, Thai   \n",
       "9           North Indian, Continental, Asian, Chinese   \n",
       "10            Modern Indian, Continental, Finger Food   \n",
       "11                              North Indian, Chinese   \n",
       "12   North Indian, Italian, Continental, Asian, Fi...   \n",
       "13   North Indian, Italian, Chinese, Turkish, Cont...   \n",
       "14        North Indian, Chinese, Italian, Continental   \n",
       "15                 North Indian, Chinese, Continental   \n",
       "16                 North Indian, Chinese, Continental   \n",
       "17        Chinese, Italian, North Indian, Continental   \n",
       "18      North Indian, Mediterranean, Chinese, Italian   \n",
       "19                         Mexican, American, Tex Mex   \n",
       "20                           North Indian, Rajasthani   \n",
       "\n",
       "                                        LOCATION RATING  \\\n",
       "0                 Connaught Place, Central Delhi    4.2   \n",
       "1   Scindia House,Connaught Place, Central Delhi      4   \n",
       "2                 Connaught Place, Central Delhi    4.1   \n",
       "3         F-Block,Connaught Place, Central Delhi    4.1   \n",
       "4         M-Block,Connaught Place, Central Delhi      4   \n",
       "5                 Connaught Place, Central Delhi    4.3   \n",
       "6         M-Block,Connaught Place, Central Delhi    4.3   \n",
       "7                 Connaught Place, Central Delhi    4.1   \n",
       "8                 Connaught Place, Central Delhi    4.3   \n",
       "9                 Connaught Place, Central Delhi    4.2   \n",
       "10                Connaught Place, Central Delhi    4.1   \n",
       "11                Connaught Place, Central Delhi      4   \n",
       "12                Connaught Place, Central Delhi    4.2   \n",
       "13                Connaught Place, Central Delhi      4   \n",
       "14                Connaught Place, Central Delhi    3.8   \n",
       "15        M-Block,Connaught Place, Central Delhi    4.3   \n",
       "16                Connaught Place, Central Delhi      4   \n",
       "17        M-Block,Connaught Place, Central Delhi    3.9   \n",
       "18                Connaught Place, Central Delhi    4.1   \n",
       "19        M-Block,Connaught Place, Central Delhi    4.3   \n",
       "20                Connaught Place, Central Delhi    4.1   \n",
       "\n",
       "                                              IMG_URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192044f",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9e366",
   "metadata": {},
   "source": [
    "i) Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "757c44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "scholar = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "afe3abb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72fa4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup12=BeautifulSoup(scholar.content)\n",
    "#print(soup12.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f85c0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.',\n",
       " '31.',\n",
       " '32.',\n",
       " '33.',\n",
       " '34.',\n",
       " '35.',\n",
       " '36.',\n",
       " '37.',\n",
       " '38.',\n",
       " '39.',\n",
       " '40.',\n",
       " '41.',\n",
       " '42.',\n",
       " '43.',\n",
       " '44.',\n",
       " '45.',\n",
       " '46.',\n",
       " '47.',\n",
       " '48.',\n",
       " '49.',\n",
       " '50.',\n",
       " '51.',\n",
       " '52.',\n",
       " '53.',\n",
       " '54.',\n",
       " '55.',\n",
       " '56.',\n",
       " '57.',\n",
       " '58.',\n",
       " '59.',\n",
       " '60.',\n",
       " '61.',\n",
       " '62.',\n",
       " '63.',\n",
       " '64.',\n",
       " '65.',\n",
       " '66.',\n",
       " '67.',\n",
       " '68.',\n",
       " '69.',\n",
       " '70.',\n",
       " '71.',\n",
       " '72.',\n",
       " '73.',\n",
       " '74.',\n",
       " '75.',\n",
       " '76.',\n",
       " '77.',\n",
       " '78.',\n",
       " '79.',\n",
       " '80.',\n",
       " '81.',\n",
       " '82.',\n",
       " '83.',\n",
       " '84.',\n",
       " '85.',\n",
       " '86.',\n",
       " '87.',\n",
       " '88.',\n",
       " '89.',\n",
       " '90.',\n",
       " '91.',\n",
       " '92.',\n",
       " '93.',\n",
       " '94.',\n",
       " '95.',\n",
       " '96.',\n",
       " '97.',\n",
       " '98.',\n",
       " '99.',\n",
       " '100.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrap scholar rank\n",
    "\n",
    "scho_rank = []  #empty list\n",
    "\n",
    "for i in soup12.find_all('td', class_=\"gsc_mvt_p\"):\n",
    "    scho_rank.append(i.text)\n",
    "    \n",
    "scho_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b82cb",
   "metadata": {},
   "source": [
    "ii) Publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0900a83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nature',\n",
       " 'The New England Journal of Medicine',\n",
       " 'Science',\n",
       " 'IEEE/CVF Conference on Computer Vision and Pattern Recognition',\n",
       " 'The Lancet',\n",
       " 'Advanced Materials',\n",
       " 'Nature Communications',\n",
       " 'Cell',\n",
       " 'International Conference on Learning Representations',\n",
       " 'Neural Information Processing Systems',\n",
       " 'JAMA',\n",
       " 'Chemical Reviews',\n",
       " 'Proceedings of the National Academy of Sciences',\n",
       " 'Angewandte Chemie',\n",
       " 'Chemical Society Reviews',\n",
       " 'Journal of the American Chemical Society',\n",
       " 'IEEE/CVF International Conference on Computer Vision',\n",
       " 'Nucleic Acids Research',\n",
       " 'International Conference on Machine Learning',\n",
       " 'Nature Medicine',\n",
       " 'Renewable and Sustainable Energy Reviews',\n",
       " 'Science of The Total Environment',\n",
       " 'Advanced Energy Materials',\n",
       " 'Journal of Clinical Oncology',\n",
       " 'ACS Nano',\n",
       " 'Journal of Cleaner Production',\n",
       " 'Advanced Functional Materials',\n",
       " 'Physical Review Letters',\n",
       " 'Scientific Reports',\n",
       " 'The Lancet Oncology',\n",
       " 'Energy & Environmental Science',\n",
       " 'IEEE Access',\n",
       " 'PLoS ONE',\n",
       " 'Science Advances',\n",
       " 'Journal of the American College of Cardiology',\n",
       " 'Applied Catalysis B: Environmental',\n",
       " 'Nature Genetics',\n",
       " 'BMJ',\n",
       " 'Circulation',\n",
       " 'European Conference on Computer Vision',\n",
       " 'International Journal of Molecular Sciences',\n",
       " 'Nature Materials',\n",
       " 'Chemical engineering journal',\n",
       " 'AAAI Conference on Artificial Intelligence',\n",
       " 'Journal of Materials Chemistry A',\n",
       " 'ACS Applied Materials & Interfaces',\n",
       " 'Nature Biotechnology',\n",
       " 'The Lancet Infectious Diseases',\n",
       " 'Frontiers in Immunology',\n",
       " 'Applied Energy',\n",
       " 'Nano Energy',\n",
       " 'Nature Energy',\n",
       " 'Meeting of the Association for Computational Linguistics (ACL)',\n",
       " 'The Astrophysical Journal',\n",
       " 'Gastroenterology',\n",
       " 'Nature Methods',\n",
       " 'IEEE Transactions on Pattern Analysis and Machine Intelligence',\n",
       " 'Cochrane Database of Systematic Reviews',\n",
       " 'Blood',\n",
       " 'Neuron',\n",
       " 'Nano Letters',\n",
       " 'Morbidity and Mortality Weekly Report',\n",
       " 'European Heart Journal',\n",
       " 'Nature Nanotechnology',\n",
       " 'ACS Catalysis',\n",
       " 'Nature Neuroscience',\n",
       " 'American Economic Review',\n",
       " 'Journal of High Energy Physics',\n",
       " 'IEEE Communications Surveys & Tutorials',\n",
       " 'Annals of Oncology',\n",
       " 'Nutrients',\n",
       " 'Accounts of Chemical Research',\n",
       " 'Immunity',\n",
       " 'Environmental Science & Technology',\n",
       " 'Nature Reviews. Molecular Cell Biology',\n",
       " 'Gut',\n",
       " 'Physical Review D',\n",
       " 'ACS Energy Letters',\n",
       " 'Monthly Notices of the Royal Astronomical Society',\n",
       " 'Conference on Empirical Methods in Natural Language Processing (EMNLP)',\n",
       " 'Clinical Infectious Diseases',\n",
       " 'Cell Metabolism',\n",
       " 'Nature Reviews Immunology',\n",
       " 'Joule',\n",
       " 'Nature Photonics',\n",
       " 'International Journal of Environmental Research and Public Health',\n",
       " 'Environmental Pollution',\n",
       " 'Computers in Human Behavior',\n",
       " 'Frontiers in Microbiology',\n",
       " 'Nature Physics',\n",
       " 'Small',\n",
       " 'Cell Reports',\n",
       " 'Molecular Cell',\n",
       " 'Clinical Cancer Research',\n",
       " 'Bioresource Technology',\n",
       " 'Journal of Business Research',\n",
       " 'Molecular Cancer',\n",
       " 'Sensors',\n",
       " 'Nature Climate Change',\n",
       " 'IEEE Internet of Things Journal']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrap publication\n",
    "\n",
    "scho_pub = []  #empty list\n",
    "\n",
    "for i in soup12.find_all('td', class_=\"gsc_mvt_t\"):\n",
    "    scho_pub.append(i.text)\n",
    "    \n",
    "scho_pub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab762f7a",
   "metadata": {},
   "source": [
    "iii) h5-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9addbb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['444',\n",
       " '432',\n",
       " '401',\n",
       " '389',\n",
       " '354',\n",
       " '312',\n",
       " '307',\n",
       " '300',\n",
       " '286',\n",
       " '278',\n",
       " '267',\n",
       " '265',\n",
       " '256',\n",
       " '245',\n",
       " '244',\n",
       " '242',\n",
       " '239',\n",
       " '238',\n",
       " '237',\n",
       " '235',\n",
       " '227',\n",
       " '225',\n",
       " '220',\n",
       " '213',\n",
       " '211',\n",
       " '211',\n",
       " '210',\n",
       " '207',\n",
       " '206',\n",
       " '202',\n",
       " '202',\n",
       " '200',\n",
       " '198',\n",
       " '197',\n",
       " '195',\n",
       " '192',\n",
       " '191',\n",
       " '190',\n",
       " '189',\n",
       " '186',\n",
       " '183',\n",
       " '181',\n",
       " '181',\n",
       " '180',\n",
       " '178',\n",
       " '177',\n",
       " '175',\n",
       " '173',\n",
       " '173',\n",
       " '173',\n",
       " '172',\n",
       " '170',\n",
       " '169',\n",
       " '167',\n",
       " '166',\n",
       " '165',\n",
       " '165',\n",
       " '165',\n",
       " '165',\n",
       " '164',\n",
       " '164',\n",
       " '163',\n",
       " '163',\n",
       " '163',\n",
       " '163',\n",
       " '162',\n",
       " '160',\n",
       " '160',\n",
       " '159',\n",
       " '159',\n",
       " '159',\n",
       " '159',\n",
       " '158',\n",
       " '158',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '154',\n",
       " '153',\n",
       " '153',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '151',\n",
       " '151',\n",
       " '150',\n",
       " '149',\n",
       " '149',\n",
       " '146',\n",
       " '146',\n",
       " '145',\n",
       " '145',\n",
       " '145',\n",
       " '144',\n",
       " '144']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrap h5 index\n",
    "\n",
    "scho_h5_ind = []  #empty list\n",
    "\n",
    "for i in soup12.find_all('a', class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    scho_h5_ind.append(i.text)\n",
    "    \n",
    "scho_h5_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd6be6",
   "metadata": {},
   "source": [
    "iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5e5cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['667',\n",
       " '780',\n",
       " '614',\n",
       " '627',\n",
       " '635',\n",
       " '418',\n",
       " '428',\n",
       " '505',\n",
       " '533',\n",
       " '436',\n",
       " '425',\n",
       " '444',\n",
       " '364',\n",
       " '332',\n",
       " '386',\n",
       " '344',\n",
       " '415',\n",
       " '550',\n",
       " '421',\n",
       " '389',\n",
       " '324',\n",
       " '311',\n",
       " '300',\n",
       " '315',\n",
       " '277',\n",
       " '273',\n",
       " '280',\n",
       " '294',\n",
       " '274',\n",
       " '329',\n",
       " '290',\n",
       " '303',\n",
       " '278',\n",
       " '294',\n",
       " '276',\n",
       " '246',\n",
       " '297',\n",
       " '307',\n",
       " '301',\n",
       " '321',\n",
       " '253',\n",
       " '265',\n",
       " '224',\n",
       " '296',\n",
       " '220',\n",
       " '223',\n",
       " '315',\n",
       " '296',\n",
       " '228',\n",
       " '217',\n",
       " '232',\n",
       " '314',\n",
       " '304',\n",
       " '234',\n",
       " '254',\n",
       " '296',\n",
       " '293',\n",
       " '243',\n",
       " '229',\n",
       " '231',\n",
       " '207',\n",
       " '302',\n",
       " '265',\n",
       " '264',\n",
       " '220',\n",
       " '248',\n",
       " '263',\n",
       " '220',\n",
       " '304',\n",
       " '243',\n",
       " '214',\n",
       " '211',\n",
       " '242',\n",
       " '214',\n",
       " '340',\n",
       " '235',\n",
       " '217',\n",
       " '212',\n",
       " '194',\n",
       " '249',\n",
       " '278',\n",
       " '211',\n",
       " '292',\n",
       " '233',\n",
       " '228',\n",
       " '225',\n",
       " '222',\n",
       " '214',\n",
       " '225',\n",
       " '222',\n",
       " '196',\n",
       " '205',\n",
       " '202',\n",
       " '201',\n",
       " '190',\n",
       " '233',\n",
       " '209',\n",
       " '201',\n",
       " '228',\n",
       " '212']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrap h5 median\n",
    "\n",
    "scho_h5_med = []  #empty list\n",
    "\n",
    "for i in soup12.find_all('span', class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    scho_h5_med.append(i.text)\n",
    "    \n",
    "scho_h5_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bb06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
